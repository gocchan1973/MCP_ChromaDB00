#!/usr/bin/env python3
"""
ChromaDB ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è©³ç´°åˆ†æ
"""
import chromadb
from chromadb.config import Settings
from pathlib import Path
import json
from datetime import datetime

def analyze_collection_details(db_path: str, collection_name: str):
    """ç‰¹å®šã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’è©³ç´°åˆ†æ"""
    print(f"ğŸ” ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è©³ç´°åˆ†æ: {collection_name}")
    print("=" * 60)
    
    try:
        client = chromadb.PersistentClient(
            path=db_path,
            settings=Settings(anonymized_telemetry=False)
        )
        
        collection = client.get_collection(collection_name)
        
        # å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—
        all_docs = collection.get()
        documents = all_docs.get('documents', [])
        metadatas = all_docs.get('metadatas', [])
        ids = all_docs.get('ids', [])
        
        print(f"ğŸ“Š ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(documents)}")
        print()
        
        # å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è©³ç´°è¡¨ç¤º
        for i, (doc_id, document, metadata) in enumerate(zip(ids, documents, metadatas)):
            print(f"ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ {i+1}")
            print(f"   ID: {doc_id}")
            print(f"   æ–‡å­—æ•°: {len(document) if document else 0}")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è©³ç´°
            if metadata:
                print(f"   ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:")
                for key, value in metadata.items():
                    if isinstance(value, str) and len(value) > 100:
                        print(f"     {key}: {value[:100]}...")
                    else:
                        print(f"     {key}: {value}")
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹ï¼ˆJSONå½¢å¼ã®å ´åˆã¯ãƒ‘ãƒ¼ã‚¹ï¼‰
            if document:
                print(f"   å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:")
                try:
                    # JSONå½¢å¼ã‹ãƒã‚§ãƒƒã‚¯
                    if document.startswith('[') or document.startswith('{'):
                        parsed = json.loads(document)
                        if isinstance(parsed, list):
                            print(f"     ä¼šè©±å±¥æ­´ ({len(parsed)} ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)")
                            for j, msg in enumerate(parsed[:3]):  # æœ€åˆã®3ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                                if isinstance(msg, dict):
                                    content = msg.get('content', str(msg))
                                    if len(content) > 80:
                                        content = content[:80] + "..."
                                    print(f"       {j+1}: {content}")
                            if len(parsed) > 3:
                                print(f"       ... (ä»– {len(parsed)-3} ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)")
                        else:
                            print(f"     JSON ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ: {str(parsed)[:200]}...")
                    else:
                        # ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
                        preview = document[:200] + "..." if len(document) > 200 else document
                        print(f"     {preview}")
                except json.JSONDecodeError:
                    # JSONã§ãªã„å ´åˆ
                    preview = document[:200] + "..." if len(document) > 200 else document
                    print(f"     {preview}")
            
            print("-" * 40)
            print()
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
        all_keys = set()
        for meta in metadatas:
            if meta:
                all_keys.update(meta.keys())
        
        print(f"ğŸ“ˆ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ")
        print(f"   ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚­ãƒ¼æ•°: {len(all_keys)}")
        print(f"   ã‚­ãƒ¼ä¸€è¦§: {list(all_keys)}")
        
        # ã‚­ãƒ¼åˆ¥çµ±è¨ˆ
        key_stats = {}
        for key in all_keys:
            values = []
            for meta in metadatas:
                if meta and key in meta:
                    values.append(meta[key])
            key_stats[key] = {
                "count": len(values),
                "unique_values": len(set(str(v) for v in values)),
                "sample_values": list(set(str(v) for v in values))[:3]
            }
        
        for key, stats in key_stats.items():
            print(f"   {key}: {stats['count']} ä»¶, ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ {stats['unique_values']} å€‹")
            if stats['sample_values']:
                print(f"     ã‚µãƒ³ãƒ—ãƒ«å€¤: {', '.join(stats['sample_values'])}")
        
        return {
            "collection_name": collection_name,
            "document_count": len(documents),
            "metadata_keys": list(all_keys),
            "key_statistics": key_stats
        }
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return {"error": str(e)}

if __name__ == "__main__":
    db_path = r"F:\å‰¯æ¥­\VSC_WorkSpace\IrukaWorkspace\shared__ChromaDB"
    
    # development_conversations ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’è©³ç´°åˆ†æ
    result1 = analyze_collection_details(db_path, "development_conversations")
    
    print("\n" + "="*80 + "\n")
    
    # test_collection ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚‚åˆ†æ
    result2 = analyze_collection_details(db_path, "test_collection")
    
    # çµæœä¿å­˜
    output_file = Path(__file__).parent / f"detailed_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({"development_conversations": result1, "test_collection": result2}, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è©³ç´°åˆ†æçµæœã¯ {output_file} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
