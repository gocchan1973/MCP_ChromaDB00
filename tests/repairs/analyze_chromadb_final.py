#!/usr/bin/env python3
"""
ChromaDBã®è©³ç´°åˆ†æãƒ„ãƒ¼ãƒ«ï¼ˆæœ€çµ‚ä¿®æ­£ç‰ˆï¼‰
"""
import chromadb
from chromadb.config import Settings
from pathlib import Path
import json
from datetime import datetime
import sqlite3

def safe_get_embedding_info(collection, doc_count):
    """ãƒ™ã‚¯ãƒˆãƒ«æƒ…å ±ã‚’å®‰å…¨ã«å–å¾—"""
    try:
        # ã¾ãšæ¤œç´¢ãƒ†ã‚¹ãƒˆã§å‹•ä½œç¢ºèª
        test_query = collection.query(query_texts=["test"], n_results=1)
        
        # æ¤œç´¢ãŒæˆåŠŸã—ãŸå ´åˆã€ãƒ™ã‚¯ãƒˆãƒ«ãŒå­˜åœ¨ã™ã‚‹ã¨åˆ¤æ–­
        if test_query and test_query.get('documents'):
            print(f"      âœ… ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢: æ­£å¸¸å‹•ä½œ")
            print(f"      ğŸ“Š æ¨å®šãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¸ˆã¿: {doc_count}/{doc_count} ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
            return {
                'has_embeddings': True,
                'vectorized_documents': doc_count,
                'vectorization_ratio': 1.0,
                'search_functional': True
            }
        else:
            print(f"      âŒ ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢: çµæœãªã—")
            return {
                'has_embeddings': False,
                'vectorized_documents': 0,
                'vectorization_ratio': 0.0,
                'search_functional': False
            }
    except Exception as search_error:
        print(f"      âš ï¸  ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {search_error}")
        
        # æ¤œç´¢ãŒå¤±æ•—ã—ãŸå ´åˆã€åˆ¥ã®æ–¹æ³•ã§ãƒ™ã‚¯ãƒˆãƒ«æƒ…å ±ã‚’ç¢ºèª
        try:
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å–å¾—ã‚’è©¦è¡Œ
            sample = collection.get(limit=1)
            if sample.get('ids'):
                print(f"      ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—: æˆåŠŸ")
                print(f"      â“ ãƒ™ã‚¯ãƒˆãƒ«çŠ¶æ…‹: ä¸æ˜ï¼ˆç›´æ¥ç¢ºèªä¸å¯ï¼‰")
                return {
                    'has_embeddings': None,  # ä¸æ˜
                    'vectorized_documents': 0,
                    'vectorization_ratio': 0.0,
                    'search_functional': False,
                    'error': 'Vector access failed but documents exist'
                }
            else:
                print(f"      âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—: å¤±æ•—")
                return {
                    'has_embeddings': False,
                    'vectorized_documents': 0,
                    'vectorization_ratio': 0.0,
                    'search_functional': False,
                    'error': 'No documents accessible'
                }
        except Exception as doc_error:
            print(f"      âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {doc_error}")
            return {
                'has_embeddings': False,
                'vectorized_documents': 0,
                'vectorization_ratio': 0.0,
                'search_functional': False,
                'error': str(doc_error)
            }

def analyze_chromadb_final(db_path: str):
    """ChromaDBã‚’è©³ç´°åˆ†æï¼ˆæœ€çµ‚ç‰ˆï¼‰"""
    print(f"ğŸ” ChromaDBåˆ†æé–‹å§‹ï¼ˆæœ€çµ‚ç‰ˆï¼‰: {db_path}")
    print("=" * 70)
    
    try:
        # ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶š
        client = chromadb.PersistentClient(
            path=db_path,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # åŸºæœ¬æƒ…å ±
        collections = client.list_collections()
        print(f"ğŸ“Š ç·ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(collections)}")
        print()
        
        total_documents = 0
        index_info = {}
        
        # å„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®è©³ç´°åˆ†æ
        for i, collection in enumerate(collections, 1):
            print(f"ğŸ“ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ {i}: {collection.name}")
            print(f"   ID: {collection.id}")
            print(f"   ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {collection.metadata}")
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°
            doc_count = collection.count()
            total_documents += doc_count
            print(f"   ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {doc_count}")
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ»ãƒ™ã‚¯ãƒˆãƒ«çŠ¶æ…‹åˆ†æ
            print(f"   ğŸ” ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çŠ¶æ…‹:")
            
            if doc_count > 0:
                # å®‰å…¨ãªãƒ™ã‚¯ãƒˆãƒ«æƒ…å ±å–å¾—
                vector_info = safe_get_embedding_info(collection, doc_count)
                
                # ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¡¨ç¤º
                try:
                    sample = collection.get(limit=2)
                    print(f"   ğŸ“„ ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:")
                    for j, (doc_id, document, metadata) in enumerate(zip(
                        sample.get('ids', []), 
                        sample.get('documents', []), 
                        sample.get('metadatas', [])
                    )):
                        print(f"     - ID: {doc_id}")
                        if document:
                            preview = document[:80] + "..." if len(document) > 80 else document
                            print(f"       å†…å®¹: {preview}")
                        if metadata:
                            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼ã®ã¿è¡¨ç¤ºï¼ˆå€¤ã¯çœç•¥ï¼‰
                            keys = list(metadata.keys()) if metadata else []
                            print(f"       ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼: {keys}")
                        print()
                except Exception as sample_error:
                    print(f"   âŒ ã‚µãƒ³ãƒ—ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {sample_error}")
                    
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ†æ
                try:
                    all_docs = collection.get()
                    metadatas = all_docs.get('metadatas', [])
                    if metadatas:
                        metadata_keys = set()
                        for meta in metadatas:
                            if meta:
                                metadata_keys.update(meta.keys())
                        print(f"   ğŸ·ï¸  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼: {list(metadata_keys)}")
                        vector_info['metadata_keys'] = list(metadata_keys)
                except Exception as meta_error:
                    print(f"   âš ï¸  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ©ãƒ¼: {meta_error}")
                    vector_info['metadata_error'] = str(meta_error)
            else:
                print(f"      ğŸ“­ ç©ºã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³")
                vector_info = {
                    'has_embeddings': False,
                    'vectorized_documents': 0,
                    'vectorization_ratio': 0.0,
                    'search_functional': False
                }
            
            index_info[collection.name] = vector_info
            print("-" * 50)
            print()
        
        # SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®è©³ç´°åˆ†æ
        print("ğŸ—„ï¸  SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è©³ç´°åˆ†æ")
        print("=" * 50)
        sqlite_file = Path(db_path) / "chroma.sqlite3"
        sqlite_info = {}
        
        if sqlite_file.exists():
            try:
                size_mb = sqlite_file.stat().st_size / (1024 * 1024)
                print(f"ğŸ“¦ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {size_mb:.2f} MB")
                sqlite_info['file_size_mb'] = size_mb
                
                with sqlite3.connect(sqlite_file) as conn:
                    cursor = conn.cursor()
                    
                    # é‡è¦ãƒ†ãƒ¼ãƒ–ãƒ«ã®æƒ…å ±ã®ã¿
                    important_tables = ['collections', 'embeddings', 'embedding_metadata', 'segments']
                    
                    for table in important_tables:
                        try:
                            cursor.execute(f"SELECT COUNT(*) FROM [{table}];")
                            count = cursor.fetchone()[0]
                            print(f"   ğŸ“ ãƒ†ãƒ¼ãƒ–ãƒ« '{table}': {count} ãƒ¬ã‚³ãƒ¼ãƒ‰")
                            sqlite_info[f'{table}_count'] = count
                        except Exception as e:
                            print(f"      âš ï¸  ãƒ†ãƒ¼ãƒ–ãƒ« '{table}' ã‚¨ãƒ©ãƒ¼: {e}")
                    
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±
                    cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='index' AND name NOT LIKE 'sqlite_%';")
                    index_count = cursor.fetchone()[0]
                    print(f"   ğŸ” ã‚«ã‚¹ã‚¿ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•°: {index_count}")
                    sqlite_info['custom_indexes'] = index_count
                    
            except Exception as e:
                print(f"âŒ SQLiteåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                sqlite_info['error'] = str(e)
        else:
            print(f"âŒ SQLiteãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {sqlite_file}")
            sqlite_info['error'] = "SQLite file not found"
        
        # ç·æ‹¬
        print("=" * 50)
        print("ğŸ“ˆ åˆ†æç·æ‹¬")
        print(f"   ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {total_documents}")
        print(f"   ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹: {db_path}")
        print(f"   åˆ†ææ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # æ©Ÿèƒ½çŠ¶æ…‹ã‚µãƒãƒªãƒ¼
        functional_collections = sum(1 for info in index_info.values() if info.get('search_functional', False))
        print(f"   æ¤œç´¢æ©Ÿèƒ½æ­£å¸¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {functional_collections}/{len(collections)}")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        consistent_collections = 0
        for col_name, info in index_info.items():
            if 'metadata_error' not in info and info.get('metadata_keys'):
                consistent_collections += 1
        
        print(f"   ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ•´åˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {consistent_collections}/{len(collections)}")
        
        if functional_collections == len(collections) and consistent_collections == len(collections):
            print(f"   ğŸ‰ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹: æœ€é©")
        elif functional_collections > 0:
            print(f"   âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹: æ­£å¸¸")
        else:
            print(f"   âš ï¸  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ…‹: å•é¡Œã‚ã‚Š")
        
        return {
            "success": True,
            "collections_count": len(collections),
            "total_documents": total_documents,
            "functional_collections": functional_collections,
            "consistent_collections": consistent_collections,
            "collections": [{"name": c.name, "id": str(c.id), "count": c.count()} for c in collections],
            "index_info": index_info,
            "sqlite_info": sqlite_info,
            "analysis_timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return {"success": False, "error": str(e)}

if __name__ == "__main__":
    # æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã‚’åˆ†æ
    target_path = r"F:\å‰¯æ¥­\VSC_WorkSpace\IrukaWorkspace\shared__ChromaDB"
    result = analyze_chromadb_final(target_path)
    
    # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚ä¿å­˜
    output_file = Path(__file__).parent / f"chromadb_analysis_final_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ åˆ†æçµæœã¯ {output_file} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
