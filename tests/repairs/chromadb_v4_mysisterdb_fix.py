#!/usr/bin/env python3
"""
ChromaDB v4 ä¿®å¾©ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ - MySisterDBæ‰‹æ³•å¿œç”¨ç‰ˆ
Embedding Functionçµ±ä¸€ã¨numpyå›é¿ã®çµ„ã¿åˆã‚ã›
"""

import chromadb
import os
import json
from datetime import datetime
from typing import Dict, List, Any
import warnings

# numpyè­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

class ChromaDBv4FixedAnalyzer:
    """MySisterDBæ‰‹æ³•ã‚’å¿œç”¨ã—ãŸChromaDB v4ä¿®å¾©ç‰ˆåˆ†æå™¨"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.client = None
        self.collection = None
        
    def connect_safely(self) -> bool:
        """å®‰å…¨ãªæ¥ç¶š"""
        try:
            self.client = chromadb.PersistentClient(path=self.db_path)
            
            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å–å¾—
            collections = self.client.list_collections()
            for coll in collections:
                if coll.name == "sister_chat_history_v4":
                    self.collection = coll
                    break
            
            print(f"âœ… å®‰å…¨æ¥ç¶šæˆåŠŸ: {self.collection.name if self.collection else 'No collection'}")
            return True
            
        except Exception as e:
            print(f"âŒ æ¥ç¶šå¤±æ•—: {e}")
            return False
    
    def analyze_via_search_only(self) -> Dict[str, Any]:
        """æ¤œç´¢æ©Ÿèƒ½ã®ã¿ã‚’ä½¿ã£ãŸãƒ™ã‚¯ã‚¿ãƒ¼åˆ†æï¼ˆMySisterDBæ‰‹æ³•ï¼‰"""
        print("\nğŸ” æ¤œç´¢çµŒç”±ãƒ™ã‚¯ã‚¿ãƒ¼åˆ†æ")
        
        results = {
            "method": "search_based_analysis",
            "status": "unknown",
            "details": {}
        }
        
        try:
            if not self.collection:
                results["status"] = "failed"
                results["details"]["error"] = "No collection"
                return results
            
            # Phase 1: åŸºæœ¬æ¤œç´¢ãƒ†ã‚¹ãƒˆ
            print("   Phase 1: åŸºæœ¬æ¤œç´¢æ©Ÿèƒ½ç¢ºèª")
            test_queries = ["ãƒ†ã‚¹ãƒˆ", "ä¼šè©±", "ã‚·ã‚¹ãƒ†ãƒ ", "AI", "å­¦ç¿’"]
            search_results = {}
            
            for query in test_queries:
                try:
                    result = self.collection.query(
                        query_texts=[query],
                        n_results=3
                    )
                    
                    result_count = len(result["documents"][0]) if result["documents"] else 0
                    search_results[query] = {
                        "success": True,
                        "count": result_count,
                        "has_distances": "distances" in result and result["distances"] is not None
                    }
                    print(f"      âœ… '{query}': {result_count}ä»¶")
                    
                except Exception as e:
                    search_results[query] = {
                        "success": False,
                        "error": str(e)
                    }
                    print(f"      âŒ '{query}': {e}")
            
            results["details"]["search_tests"] = search_results
            
            # Phase 2: é–“æ¥çš„ãªãƒ™ã‚¯ã‚¿ãƒ¼å“è³ªè©•ä¾¡
            print("   Phase 2: é–“æ¥ãƒ™ã‚¯ã‚¿ãƒ¼å“è³ªè©•ä¾¡")
            successful_searches = [k for k, v in search_results.items() if v.get("success")]
            
            if successful_searches:
                # æˆåŠŸã—ãŸæ¤œç´¢ã®é¡ä¼¼åº¦åˆ†æ
                try:
                    sample_query = successful_searches[0]
                    detailed_result = self.collection.query(
                        query_texts=[sample_query],
                        n_results=5
                    )
                    
                    if detailed_result["distances"] and detailed_result["distances"][0]:
                        distances = detailed_result["distances"][0]
                        
                        # è·é›¢çµ±è¨ˆï¼ˆnumpyä½¿ã‚ãšã«è¨ˆç®—ï¼‰
                        distance_stats = {
                            "min_distance": min(distances),
                            "max_distance": max(distances),
                            "avg_distance": sum(distances) / len(distances),
                            "distance_range": max(distances) - min(distances)
                        }
                        
                        results["details"]["vector_quality_indirect"] = distance_stats
                        print(f"      ğŸ“Š è·é›¢çµ±è¨ˆ: avg={distance_stats['avg_distance']:.3f}")
                        
                except Exception as e:
                    results["details"]["vector_analysis_error"] = str(e)
                    print(f"      âš ï¸ è©³ç´°åˆ†æã‚¹ã‚­ãƒƒãƒ—: {e}")
            
            # Phase 3: ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§è©•ä¾¡
            print("   Phase 3: ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§è©•ä¾¡")
            try:
                # éembeddingæƒ…å ±ã§ãƒ‡ãƒ¼ã‚¿ç¢ºèª
                basic_data = self.collection.get(
                    limit=10,
                    include=['documents', 'metadatas']  # embeddingsã‚’é¿ã‘ã‚‹
                )
                
                doc_count = len(basic_data["documents"])
                has_metadata = basic_data["metadatas"] and any(meta for meta in basic_data["metadatas"])
                
                results["details"]["data_integrity"] = {
                    "sample_documents": doc_count,
                    "has_metadata": has_metadata,
                    "basic_access_success": True
                }
                
                print(f"      ğŸ“„ ã‚µãƒ³ãƒ—ãƒ«æ–‡æ›¸: {doc_count}ä»¶")
                print(f"      ğŸ“‹ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {'æœ‰' if has_metadata else 'ç„¡'}")
                
            except Exception as e:
                results["details"]["data_access_error"] = str(e)
                print(f"      âŒ ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {e}")
            
            # ç·åˆè©•ä¾¡
            success_rate = len([v for v in search_results.values() if v.get("success")]) / len(search_results)
            
            if success_rate >= 0.8:
                results["status"] = "good"
                results["score"] = 85
            elif success_rate >= 0.6:
                results["status"] = "warning" 
                results["score"] = 70
            else:
                results["status"] = "failed"
                results["score"] = 30
            
            print(f"   ğŸ“Š æ¤œç´¢æˆåŠŸç‡: {success_rate:.1%}")
            
        except Exception as e:
            results["status"] = "failed"
            results["details"]["critical_error"] = str(e)
            results["score"] = 0
            print(f"   âŒ é‡å¤§ã‚¨ãƒ©ãƒ¼: {e}")
        
        return results
    
    def test_embedding_workaround(self) -> Dict[str, Any]:
        """Embeddingç›´æ¥å–å¾—ã®å›é¿ç­–ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ› ï¸ Embeddingå›é¿ç­–ãƒ†ã‚¹ãƒˆ")
        
        results = {
            "method": "embedding_workaround",
            "attempts": []
        }
        
        if not self.collection:
            return results
        
        # æ–¹æ³•1: æœ€å°é™ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
        try:
            print("   æ–¹æ³•1: 1ä»¶ãšã¤å–å¾—")
            data = self.collection.get(limit=1, include=['embeddings'])
            
            results["attempts"].append({
                "method": "single_get",
                "success": True,
                "details": f"Embeddingsæ¬¡å…ƒ: {len(data['embeddings'][0]) if data['embeddings'] else 0}"
            })
            print("      âœ… æˆåŠŸ: 1ä»¶ãšã¤å–å¾—å¯èƒ½")
            
        except Exception as e:
            results["attempts"].append({
                "method": "single_get", 
                "success": False,
                "error": str(e)
            })
            print(f"      âŒ å¤±æ•—: {e}")
        
        # æ–¹æ³•2: ã‚¯ã‚¨ãƒªçµŒç”±ã§embeddingå–å¾—
        try:
            print("   æ–¹æ³•2: ã‚¯ã‚¨ãƒªçµŒç”±embeddingå–å¾—")
            query_result = self.collection.query(
                query_texts=["test"],
                n_results=1,
                include=['embeddings', 'documents']
            )
            
            if query_result['embeddings']:
                embedding_dim = len(query_result['embeddings'][0][0])
                results["attempts"].append({
                    "method": "query_embeddings",
                    "success": True, 
                    "details": f"ã‚¯ã‚¨ãƒªçµŒç”±embeddingæ¬¡å…ƒ: {embedding_dim}"
                })
                print(f"      âœ… æˆåŠŸ: ã‚¯ã‚¨ãƒªçµŒç”± {embedding_dim}æ¬¡å…ƒ")
            else:
                results["attempts"].append({
                    "method": "query_embeddings",
                    "success": False,
                    "error": "No embeddings in query result"
                })
                
        except Exception as e:
            results["attempts"].append({
                "method": "query_embeddings",
                "success": False,
                "error": str(e)
            })
            print(f"      âŒ å¤±æ•—: {e}")
        
        return results
    
    def comprehensive_fixed_analysis(self) -> Dict[str, Any]:
        """ä¿®å¾©ç‰ˆç·åˆåˆ†æ"""
        print("\nğŸ”¬ ChromaDB v4 ä¿®å¾©ç‰ˆç·åˆåˆ†æ")
        print("="*60)
        
        final_report = {
            "analysis_timestamp": datetime.now().isoformat(),
            "approach": "MySisterDB_inspired_fix",
            "database_path": self.db_path,
            "analysis_results": []
        }
        
        if not self.connect_safely():
            final_report["status"] = "connection_failed"
            return final_report
        
        # æ¤œç´¢ãƒ™ãƒ¼ã‚¹åˆ†æï¼ˆãƒ¡ã‚¤ãƒ³æ‰‹æ³•ï¼‰
        search_analysis = self.analyze_via_search_only()
        final_report["analysis_results"].append(search_analysis)
        
        # Embeddingå›é¿ç­–ãƒ†ã‚¹ãƒˆ
        workaround_test = self.test_embedding_workaround()
        final_report["analysis_results"].append(workaround_test)
        
        # ç·åˆåˆ¤å®š
        main_score = search_analysis.get("score", 0)
        workaround_success = any(a.get("success") for a in workaround_test.get("attempts", []))
        
        if main_score >= 80 and workaround_success:
            final_report["overall_status"] = "RECOVERABLE"
            final_report["recommendation"] = "ä¿®å¾©å¯èƒ½ - embeddingå›é¿ã§ç¶™ç¶šå­¦ç¿’å¯¾å¿œ"
        elif main_score >= 60:
            final_report["overall_status"] = "PARTIALLY_FUNCTIONAL"
            final_report["recommendation"] = "éƒ¨åˆ†æ©Ÿèƒ½ - åŸºæœ¬æ¤œç´¢ã¯åˆ©ç”¨å¯èƒ½"
        else:
            final_report["overall_status"] = "MIGRATION_REQUIRED"
            final_report["recommendation"] = "ç§»è¡Œæ¨å¥¨ - æ ¹æœ¬çš„ãªå•é¡Œã‚ã‚Š"
        
        # ä¿®å¾©æˆ¦ç•¥ææ¡ˆ
        final_report["recovery_strategy"] = self.generate_recovery_strategy(search_analysis, workaround_test)
        
        print(f"\nğŸ¯ ç·åˆåˆ¤å®š: {final_report['overall_status']}")
        print(f"ğŸ’¡ æ¨å¥¨: {final_report['recommendation']}")
        
        return final_report
    
    def generate_recovery_strategy(self, search_analysis: Dict, workaround_test: Dict) -> Dict[str, Any]:
        """å›å¾©æˆ¦ç•¥ã‚’ç”Ÿæˆ"""
        
        strategy = {
            "immediate_actions": [],
            "medium_term_plan": [],
            "long_term_vision": []
        }
        
        # æ¤œç´¢æ©Ÿèƒ½ãŒå‹•ä½œã—ã¦ã„ã‚‹å ´åˆ
        if search_analysis.get("score", 0) >= 60:
            strategy["immediate_actions"].extend([
                "æ¤œç´¢æ©Ÿèƒ½ãƒ™ãƒ¼ã‚¹ã®åˆ†æç¶™ç¶š",
                "embeddingç›´æ¥å–å¾—ã‚’å›é¿ã—ãŸé‹ç”¨",
                "æ¤œç´¢å“è³ªã®ç¶™ç¶šç›£è¦–"
            ])
            
            strategy["medium_term_plan"].extend([
                "embeddingå–å¾—ã®ä»£æ›¿æ‰‹æ³•é–‹ç™º",
                "numpyäº’æ›æ€§å•é¡Œã®æ®µéšçš„è§£æ±º",
                "ChromaDBãƒãƒ¼ã‚¸ãƒ§ãƒ³æœ€é©åŒ–æ¤œè¨"
            ])
        
        # Embeddingå›é¿ç­–ãŒæˆåŠŸã—ã¦ã„ã‚‹å ´åˆ
        if any(a.get("success") for a in workaround_test.get("attempts", [])):
            strategy["immediate_actions"].append("embeddingå›é¿ç­–ã®æœ¬æ ¼æ¡ç”¨")
            strategy["medium_term_plan"].append("å›é¿ç­–ãƒ™ãƒ¼ã‚¹ã®ç¶™ç¶šå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰")
        
        strategy["long_term_vision"] = [
            "å®‰å®šã—ãŸç¶™ç¶šå­¦ç¿’ç’°å¢ƒã®ç¢ºç«‹",
            "æ¬¡ä¸–ä»£ãƒ™ã‚¯ã‚¿ãƒ¼DBæŠ€è¡“ã¸ã®æ®µéšç§»è¡Œ",
            "AIçŸ¥è­˜è“„ç©ã‚·ã‚¹ãƒ†ãƒ ã®å®Œæˆ"
        ]
        
        return strategy

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ ChromaDB v4 MySisterDBæ‰‹æ³•å¿œç”¨ä¿®å¾©ãƒ†ã‚¹ãƒˆ")
    
    v4_db_path = r"F:\å‰¯æ¥­\VSC_WorkSpace\IrukaWorkspace\shared__ChromaDB_v4"
    
    analyzer = ChromaDBv4FixedAnalyzer(v4_db_path)
    report = analyzer.comprehensive_fixed_analysis()
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    output_file = r"f:\å‰¯æ¥­\VSC_WorkSpace\MCP_ChromaDB00\chromadb_v4_recovery_analysis.json"
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nğŸ’¾ ä¿®å¾©åˆ†æãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {output_file}")
    except Exception as e:
        print(f"âš ï¸ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å¤±æ•—: {e}")
    
    return report

if __name__ == "__main__":
    report = main()
