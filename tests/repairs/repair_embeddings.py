#!/usr/bin/env python3
"""
ChromaDBã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®embeddingsä¿®å¾©ãƒ„ãƒ¼ãƒ«
æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®embeddingsçŠ¶æ…‹ã‚’åˆ†æã—ã€å¿…è¦ã«å¿œã˜ã¦ä¿®å¾©
"""
import chromadb
from chromadb.config import Settings
from pathlib import Path
import json
from datetime import datetime
import numpy as np

def analyze_embeddings_status():
    """æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®embeddingsçŠ¶æ…‹ã‚’è©³ç´°åˆ†æ"""
    
    db_path = r"F:\å‰¯æ¥­\VSC_WorkSpace\IrukaWorkspace\shared__ChromaDB"
    
    print("ğŸ” ChromaDBã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®embeddingsçŠ¶æ…‹åˆ†æé–‹å§‹")
    print("=" * 60)
    print(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹: {db_path}")
    print()
    
    try:
        # ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶š
        client = chromadb.PersistentClient(
            path=db_path,
            settings=Settings(anonymized_telemetry=False)
        )
        
        collections = client.list_collections()
        print(f"ğŸ“Š ç·ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(collections)}")
        print()
        
        analysis_results = {}
        
        for collection in collections:
            print(f"ğŸ“ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {collection.name}")
            print("-" * 40)
            
            # åŸºæœ¬æƒ…å ±
            doc_count = collection.count()
            print(f"   ğŸ“Š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {doc_count}")
            
            collection_analysis = {
                'name': collection.name,
                'document_count': doc_count,
                'embeddings_analysis': {}
            }
            
            if doc_count > 0:
                try:
                    # æœ€åˆã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®embeddingsã‚’ãƒ†ã‚¹ãƒˆå–å¾—
                    test_data = collection.get(include=['embeddings'], limit=1)
                    test_embeddings = test_data.get('embeddings', [])
                    
                    print(f"   ğŸ§ª ãƒ†ã‚¹ãƒˆembeddingså–å¾—: æˆåŠŸ")
                    print(f"   ğŸ”¢ å–å¾—ã•ã‚ŒãŸembeddingsæ•°: {len(test_embeddings)}")
                    
                    if test_embeddings and len(test_embeddings) > 0:
                        first_embedding = test_embeddings[0]
                        if first_embedding is not None:
                            # embeddingã®è©³ç´°åˆ†æ
                            embedding_type = type(first_embedding).__name__
                            print(f"   ğŸ“ Embeddingå‹: {embedding_type}")
                            
                            if hasattr(first_embedding, '__len__'):
                                try:
                                    embedding_dim = len(first_embedding)
                                    print(f"   ğŸ“ Embeddingæ¬¡å…ƒ: {embedding_dim}")
                                    collection_analysis['embeddings_analysis']['dimension'] = embedding_dim
                                    collection_analysis['embeddings_analysis']['type'] = embedding_type
                                    collection_analysis['embeddings_analysis']['has_valid_embeddings'] = True
                                    
                                    # ã‚µãƒ³ãƒ—ãƒ«å€¤ã®ç¢ºèª
                                    if hasattr(first_embedding, 'dtype'):
                                        print(f"   ğŸ¯ ãƒ‡ãƒ¼ã‚¿å‹: {first_embedding.dtype}")
                                        collection_analysis['embeddings_analysis']['dtype'] = str(first_embedding.dtype)
                                    
                                    # å€¤ã®ç¯„å›²ç¢ºèª
                                    try:
                                        embedding_array = np.array(first_embedding)
                                        min_val = float(np.min(embedding_array))
                                        max_val = float(np.max(embedding_array))
                                        mean_val = float(np.mean(embedding_array))
                                        print(f"   ğŸ“ˆ å€¤ç¯„å›²: {min_val:.4f} ~ {max_val:.4f} (å¹³å‡: {mean_val:.4f})")
                                        collection_analysis['embeddings_analysis']['value_range'] = {
                                            'min': min_val,
                                            'max': max_val,
                                            'mean': mean_val
                                        }
                                    except Exception as e:
                                        print(f"   âš ï¸  å€¤ç¯„å›²åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                                    
                                except Exception as e:
                                    print(f"   âŒ Embeddingæ¬¡å…ƒå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                                    collection_analysis['embeddings_analysis']['has_valid_embeddings'] = False
                                    collection_analysis['embeddings_analysis']['error'] = str(e)
                            else:
                                print(f"   âŒ Embeddingé•·ã•å–å¾—ä¸å¯")
                                collection_analysis['embeddings_analysis']['has_valid_embeddings'] = False
                        else:
                            print(f"   âŒ EmbeddingãŒ None")
                            collection_analysis['embeddings_analysis']['has_valid_embeddings'] = False
                    else:
                        print(f"   âŒ Embeddingsãƒªã‚¹ãƒˆãŒç©º")
                        collection_analysis['embeddings_analysis']['has_valid_embeddings'] = False
                    
                    # å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®embeddingsçŠ¶æ…‹ç¢ºèªï¼ˆå®‰å…¨ãªæ–¹æ³•ï¼‰
                    print(f"   ğŸ”„ å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®embeddingsçŠ¶æ…‹ç¢ºèªä¸­...")
                    try:
                        # æ¤œç´¢ãƒ†ã‚¹ãƒˆã§embeddingsæ©Ÿèƒ½ç¢ºèª
                        search_test = collection.query(
                            query_texts=["test query"],
                            n_results=min(3, doc_count)
                        )
                        
                        if search_test and search_test.get('documents'):
                            print(f"   âœ… æ¤œç´¢æ©Ÿèƒ½: æ­£å¸¸å‹•ä½œ")
                            print(f"   ğŸ“‹ æ¤œç´¢çµæœæ•°: {len(search_test.get('documents', []))}")
                            collection_analysis['embeddings_analysis']['search_functional'] = True
                        else:
                            print(f"   âŒ æ¤œç´¢æ©Ÿèƒ½: ç•°å¸¸")
                            collection_analysis['embeddings_analysis']['search_functional'] = False
                    
                    except Exception as search_error:
                        print(f"   âŒ æ¤œç´¢ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {search_error}")
                        collection_analysis['embeddings_analysis']['search_functional'] = False
                        collection_analysis['embeddings_analysis']['search_error'] = str(search_error)
                    
                    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç¢ºèª
                    sample_data = collection.get(include=['documents', 'metadatas'], limit=2)
                    print(f"   ğŸ“„ ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:")
                    for i, (doc_id, document) in enumerate(zip(
                        sample_data.get('ids', []), 
                        sample_data.get('documents', [])
                    )):
                        preview = document[:60] + "..." if len(document) > 60 else document
                        print(f"      {i+1}. {doc_id}: {preview}")
                    
                except Exception as e:
                    print(f"   âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                    collection_analysis['embeddings_analysis']['error'] = str(e)
            
            else:
                print(f"   ğŸ“­ ç©ºã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³")
                collection_analysis['embeddings_analysis']['has_valid_embeddings'] = False
            
            analysis_results[collection.name] = collection_analysis
            print()
        
        # åˆ†æçµæœã®ã‚µãƒãƒªãƒ¼
        print("ğŸ¯ åˆ†æã‚µãƒãƒªãƒ¼")
        print("=" * 40)
        
        total_collections = len(analysis_results)
        functional_collections = sum(1 for result in analysis_results.values() 
                                   if result['embeddings_analysis'].get('search_functional', False))
        
        print(f"ğŸ“Š ç·ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ•°: {total_collections}")
        print(f"âœ… æ¤œç´¢æ©Ÿèƒ½æ­£å¸¸: {functional_collections}")
        print(f"âŒ æ¤œç´¢æ©Ÿèƒ½ç•°å¸¸: {total_collections - functional_collections}")
        
        for name, result in analysis_results.items():
            embeddings_info = result['embeddings_analysis']
            status = "âœ…" if embeddings_info.get('search_functional', False) else "âŒ"
            dimension = embeddings_info.get('dimension', 'N/A')
            print(f"   {status} {name}: {result['document_count']}ä»¶, æ¬¡å…ƒ:{dimension}")
        
        # çµæœã‚’JSONã§ä¿å­˜
        report_file = Path(__file__).parent / f"embeddings_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump({
                'analysis_timestamp': datetime.now().isoformat(),
                'database_path': db_path,
                'total_collections': total_collections,
                'functional_collections': functional_collections,
                'collections': analysis_results
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ åˆ†æçµæœã‚’ä¿å­˜: {report_file}")
        
        return analysis_results
        
    except Exception as e:
        print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None

def repair_embeddings_if_needed(analysis_results):
    """å¿…è¦ã«å¿œã˜ã¦embeddingsã‚’ä¿®å¾©"""
    
    if not analysis_results:
        print("âŒ åˆ†æçµæœãŒãªã„ãŸã‚ä¿®å¾©ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        return False
    
    print("\nğŸ”§ Embeddingsä¿®å¾©ãƒã‚§ãƒƒã‚¯é–‹å§‹")
    print("=" * 50)
    
    db_path = r"F:\å‰¯æ¥­\VSC_WorkSpace\IrukaWorkspace\shared__ChromaDB"
    
    # ä¿®å¾©ãŒå¿…è¦ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç‰¹å®š
    needs_repair = []
    for name, result in analysis_results.items():
        embeddings_info = result['embeddings_analysis']
        if not embeddings_info.get('search_functional', False):
            needs_repair.append(name)
            print(f"ğŸ”´ ä¿®å¾©å¿…è¦: {name}")
        else:
            print(f"ğŸŸ¢ æ­£å¸¸: {name}")
    
    if not needs_repair:
        print("âœ… å…¨ã¦ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒæ­£å¸¸ã§ã™ã€‚ä¿®å¾©ã¯ä¸è¦ã§ã™ã€‚")
        return True
    
    print(f"\nğŸ› ï¸  {len(needs_repair)}å€‹ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¿®å¾©ã—ã¾ã™: {', '.join(needs_repair)}")
    
    try:
        client = chromadb.PersistentClient(
            path=db_path,
            settings=Settings(anonymized_telemetry=False)
        )
        
        for collection_name in needs_repair:
            print(f"\nğŸ”§ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{collection_name}' ã®ä¿®å¾©ä¸­...")
            
            try:
                collection = client.get_collection(collection_name)
                
                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’å–å¾—ï¼ˆembeddingsãªã—ï¼‰
                all_data = collection.get(include=['documents', 'metadatas'])
                
                ids = all_data.get('ids', [])
                documents = all_data.get('documents', [])
                metadatas = all_data.get('metadatas', [])
                
                print(f"   ğŸ“Š å–å¾—ãƒ‡ãƒ¼ã‚¿: {len(ids)}ä»¶")
                
                if ids and documents:
                    # ä¸€æ™‚çš„ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
                    temp_collection_name = f"{collection_name}_temp_repair"
                    
                    # æ—¢å­˜ã®ä¸€æ™‚ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤
                    try:
                        client.delete_collection(temp_collection_name)
                    except:
                        pass
                    
                    # æ–°ã—ã„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆï¼ˆembeddingsã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ï¼‰
                    print(f"   ğŸ†• ä¸€æ™‚ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ: {temp_collection_name}")
                    temp_collection = client.create_collection(
                        name=temp_collection_name,
                        metadata={"repair_source": collection_name, "repair_timestamp": datetime.now().isoformat()}
                    )
                    
                    # ãƒãƒƒãƒã§ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ï¼ˆembeddingsã¯è‡ªå‹•ç”Ÿæˆï¼‰
                    batch_size = 20
                    for i in range(0, len(ids), batch_size):
                        end_idx = min(i + batch_size, len(ids))
                        
                        batch_ids = ids[i:end_idx]
                        batch_documents = documents[i:end_idx]
                        batch_metadatas = metadatas[i:end_idx] if metadatas else None
                        
                        temp_collection.add(
                            ids=batch_ids,
                            documents=batch_documents,
                            metadatas=batch_metadatas
                        )
                        
                        print(f"   â³ ãƒãƒƒãƒ {i//batch_size + 1}: {len(batch_ids)}ä»¶è¿½åŠ ")
                    
                    # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
                    test_result = temp_collection.query(query_texts=["test"], n_results=1)
                    if test_result and test_result.get('documents'):
                        print(f"   âœ… ä¿®å¾©ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ¤œç´¢ãƒ†ã‚¹ãƒˆ: æˆåŠŸ")
                        
                        # å…ƒã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤
                        client.delete_collection(collection_name)
                        print(f"   ğŸ—‘ï¸  å…ƒã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‰Šé™¤: {collection_name}")
                        
                        # ä¸€æ™‚ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å…ƒã®åå‰ã«ãƒªãƒãƒ¼ãƒ 
                        # ChromaDBã¯ç›´æ¥ãƒªãƒãƒ¼ãƒ ã§ããªã„ãŸã‚ã€æ–°ã—ã„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
                        repaired_collection = client.create_collection(
                            name=collection_name,
                            metadata={"repaired": True, "repair_timestamp": datetime.now().isoformat()}
                        )
                        
                        # ãƒ‡ãƒ¼ã‚¿ã‚’ç§»è¡Œ
                        temp_data = temp_collection.get(include=['documents', 'metadatas', 'embeddings'])
                        temp_ids = temp_data.get('ids', [])
                        temp_documents = temp_data.get('documents', [])
                        temp_metadatas = temp_data.get('metadatas', [])
                        temp_embeddings = temp_data.get('embeddings', [])
                        
                        for i in range(0, len(temp_ids), batch_size):
                            end_idx = min(i + batch_size, len(temp_ids))
                            
                            repaired_collection.add(
                                ids=temp_ids[i:end_idx],
                                documents=temp_documents[i:end_idx],
                                metadatas=temp_metadatas[i:end_idx] if temp_metadatas else None,
                                embeddings=temp_embeddings[i:end_idx] if temp_embeddings else None
                            )
                        
                        # ä¸€æ™‚ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤
                        client.delete_collection(temp_collection_name)
                        
                        # æœ€çµ‚ãƒ†ã‚¹ãƒˆ
                        final_test = repaired_collection.query(query_texts=["test"], n_results=1)
                        if final_test and final_test.get('documents'):
                            print(f"   ğŸ‰ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{collection_name}' ä¿®å¾©å®Œäº†!")
                        else:
                            print(f"   âŒ æœ€çµ‚ãƒ†ã‚¹ãƒˆå¤±æ•—: {collection_name}")
                    else:
                        print(f"   âŒ ä¿®å¾©ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ¤œç´¢ãƒ†ã‚¹ãƒˆå¤±æ•—")
                        # ä¸€æ™‚ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤
                        client.delete_collection(temp_collection_name)
                
                else:
                    print(f"   âš ï¸  ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {collection_name}")
                    
            except Exception as e:
                print(f"   âŒ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{collection_name}' ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        print(f"\nğŸ¯ ä¿®å¾©å‡¦ç†å®Œäº†!")
        return True
        
    except Exception as e:
        print(f"âŒ ä¿®å¾©å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸš€ ChromaDB Embeddingsä¿®å¾©ãƒ„ãƒ¼ãƒ«é–‹å§‹")
    print("=" * 60)
    
    # 1. åˆ†æå®Ÿè¡Œ
    analysis_results = analyze_embeddings_status()
    
    if analysis_results:
        # 2. å¿…è¦ã«å¿œã˜ã¦ä¿®å¾©
        repair_success = repair_embeddings_if_needed(analysis_results)
        
        if repair_success:
            print("\nâœ… å…¨å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ!")
        else:
            print("\nâŒ ä¿®å¾©å‡¦ç†ã«å•é¡ŒãŒã‚ã‚Šã¾ã—ãŸ")
    else:
        print("\nâŒ åˆ†æã«å¤±æ•—ã—ãŸãŸã‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™")
