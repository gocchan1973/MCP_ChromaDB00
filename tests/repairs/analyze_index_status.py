#!/usr/bin/env python3
"""
ChromaDBã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çŠ¶æ…‹ã®è©³ç´°åˆ†æãƒ„ãƒ¼ãƒ«
"""
import chromadb
from chromadb.config import Settings
from pathlib import Path
import json
from datetime import datetime
import sqlite3

def analyze_chromadb_index_status(db_path: str):
    """ChromaDBã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çŠ¶æ…‹ã‚’è©³ç´°åˆ†æ"""
    print(f"ğŸ” ChromaDBã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çŠ¶æ…‹åˆ†æ: {db_path}")
    print("=" * 70)
    
    try:
        # ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶š
        client = chromadb.PersistentClient(
            path=db_path,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # åŸºæœ¬æƒ…å ±
        collections = client.list_collections()
        print(f"ğŸ“Š ç·ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(collections)}")
        print()
        
        # SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç›´æ¥åˆ†æ
        sqlite_file = Path(db_path) / "chroma.sqlite3"
        index_analysis = {}
        
        if sqlite_file.exists():
            print("ğŸ—„ï¸  SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç›´æ¥åˆ†æ")
            print("-" * 50)
            
            with sqlite3.connect(sqlite_file) as conn:
                cursor = conn.cursor()
                
                # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±
                cursor.execute("SELECT id, name, dimension FROM collections;")
                db_collections = cursor.fetchall()
                
                for col_id, col_name, dimension in db_collections:
                    print(f"ğŸ“ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {col_name}")
                    print(f"   ID: {col_id}")
                    print(f"   è¨­å®šæ¬¡å…ƒæ•°: {dimension}")
                    
                    # ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª
                    cursor.execute("SELECT COUNT(*) FROM embeddings WHERE segment_id IN (SELECT id FROM segments WHERE collection = ?);", (col_id,))
                    embedding_count = cursor.fetchone()[0]
                    
                    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±
                    cursor.execute("SELECT id, type, scope FROM segments WHERE collection = ?;", (col_id,))
                    segments = cursor.fetchall()
                    
                    print(f"   ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(segments)}")
                    for seg_id, seg_type, scope in segments:
                        print(f"     - ID: {seg_id}, ã‚¿ã‚¤ãƒ—: {seg_type}, ã‚¹ã‚³ãƒ¼ãƒ—: {scope}")
                    
                    print(f"   åŸ‹ã‚è¾¼ã¿ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {embedding_count}")
                    
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ•°
                    cursor.execute("SELECT COUNT(*) FROM embedding_metadata WHERE id IN (SELECT id FROM embeddings WHERE segment_id IN (SELECT id FROM segments WHERE collection = ?));", (col_id,))
                    metadata_count = cursor.fetchone()[0]
                    print(f"   ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {metadata_count}")
                    
                    # ãƒ•ãƒ«ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ãƒ‡ãƒ¼ã‚¿
                    cursor.execute("SELECT COUNT(*) FROM embedding_fulltext_search;")
                    fulltext_count = cursor.fetchone()[0]
                    print(f"   ãƒ•ãƒ«ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {fulltext_count}")
                    
                    # ãƒ™ã‚¯ãƒˆãƒ«ã‚­ãƒ¥ãƒ¼çŠ¶æ³
                    cursor.execute("SELECT COUNT(*) FROM embeddings_queue;")
                    queue_count = cursor.fetchone()[0]
                    print(f"   ãƒ™ã‚¯ãƒˆãƒ«å‡¦ç†ã‚­ãƒ¥ãƒ¼: {queue_count}")
                    
                    # å®Ÿéš›ã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª
                    cursor.execute("""
                        SELECT eq.id, eq.vector, eq.metadata 
                        FROM embeddings_queue eq 
                        WHERE eq.id IN (
                            SELECT embedding_id FROM embeddings 
                            WHERE segment_id IN (
                                SELECT id FROM segments WHERE collection = ?
                            )
                        ) 
                        LIMIT 3
                    """, (col_id,))
                    vector_samples = cursor.fetchall()
                    
                    if vector_samples:
                        print(f"   âœ… ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿: å­˜åœ¨")
                        for vec_id, vector, metadata in vector_samples:
                            if vector:
                                # ãƒ™ã‚¯ãƒˆãƒ«ã®é•·ã•ã‚’ç¢ºèª
                                import pickle
                                try:
                                    vec_data = pickle.loads(vector)
                                    if hasattr(vec_data, '__len__'):
                                        print(f"     ã‚µãƒ³ãƒ—ãƒ« {vec_id}: æ¬¡å…ƒæ•° {len(vec_data)}")
                                    else:
                                        print(f"     ã‚µãƒ³ãƒ—ãƒ« {vec_id}: ãƒ™ã‚¯ãƒˆãƒ«å½¢å¼ä¸æ˜")
                                except:
                                    print(f"     ã‚µãƒ³ãƒ—ãƒ« {vec_id}: ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ {len(vector)} bytes")
                    else:
                        print(f"   âŒ ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿: ãªã—")
                    
                    index_analysis[col_name] = {
                        'collection_id': col_id,
                        'dimension': dimension,
                        'segments': len(segments),
                        'embedding_records': embedding_count,
                        'metadata_records': metadata_count,
                        'fulltext_records': fulltext_count,
                        'queue_records': queue_count,
                        'has_vectors': len(vector_samples) > 0
                    }
                    
                    print("-" * 40)
                
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±
                print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±")
                print("-" * 40)
                cursor.execute("SELECT name, tbl_name, sql FROM sqlite_master WHERE type='index' AND name NOT LIKE 'sqlite_%';")
                indexes = cursor.fetchall()
                
                for index_name, table_name, sql in indexes:
                    print(f"ğŸ” {index_name}")
                    print(f"   ãƒ†ãƒ¼ãƒ–ãƒ«: {table_name}")
                    if sql:
                        print(f"   SQL: {sql}")
                    print()
                
                # å…¨ä½“çµ±è¨ˆ
                print("ğŸ“ˆ å…¨ä½“çµ±è¨ˆ")
                print("-" * 30)
                cursor.execute("SELECT COUNT(*) FROM embeddings;")
                total_embeddings = cursor.fetchone()[0]
                cursor.execute("SELECT COUNT(*) FROM embedding_metadata;")
                total_metadata = cursor.fetchone()[0]
                cursor.execute("SELECT COUNT(*) FROM embeddings_queue;")
                total_queue = cursor.fetchone()[0]
                
                print(f"ç·åŸ‹ã‚è¾¼ã¿ãƒ¬ã‚³ãƒ¼ãƒ‰: {total_embeddings}")
                print(f"ç·ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰: {total_metadata}")
                print(f"ç·ã‚­ãƒ¥ãƒ¼ãƒ¬ã‚³ãƒ¼ãƒ‰: {total_queue}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
                size_mb = sqlite_file.stat().st_size / (1024 * 1024)
                print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º: {size_mb:.2f} MB")
        
        # ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§ã®ç¢ºèª
        print("\nğŸ” ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆ†æ")
        print("-" * 40)
        
        total_documents = 0
        for collection in collections:
            doc_count = collection.count()
            total_documents += doc_count
            print(f"ğŸ“ {collection.name}: {doc_count} ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
            
            # ç°¡å˜ãªæ¤œç´¢ãƒ†ã‚¹ãƒˆ
            try:
                if doc_count > 0:
                    test_result = collection.query(query_texts=["test"], n_results=1)
                    if test_result.get('documents'):
                        print(f"   âœ… æ¤œç´¢æ©Ÿèƒ½: æ­£å¸¸")
                    else:
                        print(f"   âš ï¸  æ¤œç´¢æ©Ÿèƒ½: çµæœãªã—")
                else:
                    print(f"   ğŸ“­ ç©ºã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³")
            except Exception as e:
                print(f"   âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        
        print(f"\nğŸ“Š ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {total_documents}")
        print(f"ğŸ“… åˆ†ææ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        return {
            "success": True,
            "total_documents": total_documents,
            "collections_count": len(collections),
            "index_analysis": index_analysis,
            "analysis_timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return {"success": False, "error": str(e)}

if __name__ == "__main__":
    target_path = r"F:\å‰¯æ¥­\VSC_WorkSpace\IrukaWorkspace\shared__ChromaDB"
    result = analyze_chromadb_index_status(target_path)
    
    # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_file = Path(__file__).parent / f"chromadb_index_status_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ è©³ç´°åˆ†æçµæœã¯ {output_file} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
