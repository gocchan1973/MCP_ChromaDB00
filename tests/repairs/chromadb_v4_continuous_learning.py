#!/usr/bin/env python3
"""
ChromaDB v4 ç¶™ç¶šå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  - æ¤œç´¢ãƒ™ãƒ¼ã‚¹å®Ÿè£…
embeddingç›´æ¥æ“ä½œã‚’å®Œå…¨å›é¿ã—ãŸå­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
"""

import chromadb
import json
from datetime import datetime
from typing import Dict, List, Any, Optional

class SearchBasedLearningSystem:
    """æ¤œç´¢æ©Ÿèƒ½ãƒ™ãƒ¼ã‚¹ã®ç¶™ç¶šå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.client = None
        self.collection = None
        self.learning_metrics = {
            "documents_added": 0,
            "search_quality_improvements": 0,
            "last_learning_session": None
        }
        
    def initialize(self) -> bool:
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        try:
            self.client = chromadb.PersistentClient(path=self.db_path)
            
            collections = self.client.list_collections()
            for coll in collections:
                if coll.name == "sister_chat_history_v4":
                    self.collection = coll
                    break
            
            if self.collection:
                print(f"âœ… å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–æˆåŠŸ: {self.collection.count()} documents")
                return True
            else:
                print("âŒ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
                
        except Exception as e:
            print(f"âŒ åˆæœŸåŒ–å¤±æ•—: {e}")
            return False
    
    def add_new_knowledge(self, text: str, metadata: Dict[str, Any] = None) -> bool:
        """æ–°ã—ã„çŸ¥è­˜ã‚’å®‰å…¨ã«è¿½åŠ ï¼ˆembeddingç›´æ¥æ“ä½œãªã—ï¼‰"""
        try:
            if not self.collection:
                return False
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«å­¦ç¿’æƒ…å ±ã‚’è¿½åŠ 
            enhanced_metadata = metadata or {}
            enhanced_metadata.update({
                "added_by": "search_based_learning",
                "timestamp": datetime.now().isoformat(),
                "learning_session": self.learning_metrics["documents_added"] + 1
            })
            
            # æ–‡æ›¸ã‚’è¿½åŠ ï¼ˆChromaDBãŒè‡ªå‹•ã§embeddingç”Ÿæˆï¼‰
            document_id = f"learned_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{self.learning_metrics['documents_added']}"
            
            self.collection.add(
                documents=[text],
                metadatas=[enhanced_metadata],
                ids=[document_id]
            )
            
            self.learning_metrics["documents_added"] += 1
            self.learning_metrics["last_learning_session"] = datetime.now().isoformat()
            
            print(f"âœ… æ–°ã—ã„çŸ¥è­˜è¿½åŠ æˆåŠŸ: {document_id}")
            return True
            
        except Exception as e:
            print(f"âŒ çŸ¥è­˜è¿½åŠ å¤±æ•—: {e}")
            return False
    
    def assess_search_quality(self, test_queries: List[str]) -> Dict[str, Any]:
        """æ¤œç´¢å“è³ªè©•ä¾¡ï¼ˆembeddingç›´æ¥æ“ä½œãªã—ï¼‰"""
        quality_report = {
            "test_timestamp": datetime.now().isoformat(),
            "total_queries": len(test_queries),
            "results": {},
            "overall_quality": 0.0
        }
        
        try:
            total_relevance = 0
            successful_queries = 0
            
            for query in test_queries:
                try:
                    results = self.collection.query(
                        query_texts=[query],
                        n_results=5
                    )
                    
                    result_count = len(results["documents"][0]) if results["documents"] else 0
                    
                    # è·é›¢ãƒ™ãƒ¼ã‚¹ã®å“è³ªè©•ä¾¡
                    quality_score = 0.0
                    if results["distances"] and results["distances"][0]:
                        distances = results["distances"][0]
                        # è·é›¢ãŒå°ã•ã„ã»ã©é«˜å“è³ªï¼ˆæœ€å¤§1.0-æœ€å°è·é›¢ï¼‰
                        if distances:
                            quality_score = max(0, 1.0 - min(distances))
                    
                    quality_report["results"][query] = {
                        "result_count": result_count,
                        "quality_score": quality_score,
                        "success": True
                    }
                    
                    total_relevance += quality_score
                    successful_queries += 1
                    
                except Exception as e:
                    quality_report["results"][query] = {
                        "success": False,
                        "error": str(e)
                    }
            
            if successful_queries > 0:
                quality_report["overall_quality"] = total_relevance / successful_queries
                quality_report["success_rate"] = successful_queries / len(test_queries)
            
            return quality_report
            
        except Exception as e:
            quality_report["error"] = str(e)
            return quality_report
    
    def adaptive_learning_cycle(self, new_texts: List[str], test_queries: List[str]) -> Dict[str, Any]:
        """é©å¿œçš„å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«"""
        cycle_report = {
            "cycle_start": datetime.now().isoformat(),
            "phase_results": {}
        }
        
        try:
            # Phase 1: å­¦ç¿’å‰ã®å“è³ªæ¸¬å®š
            print("\nğŸ“Š Phase 1: å­¦ç¿’å‰å“è³ªæ¸¬å®š")
            pre_quality = self.assess_search_quality(test_queries)
            cycle_report["phase_results"]["pre_learning_quality"] = pre_quality
            print(f"   å­¦ç¿’å‰å“è³ª: {pre_quality['overall_quality']:.3f}")
            
            # Phase 2: æ–°ã—ã„çŸ¥è­˜ã®è¿½åŠ 
            print("\nğŸ“š Phase 2: æ–°ã—ã„çŸ¥è­˜è¿½åŠ ")
            added_count = 0
            for i, text in enumerate(new_texts):
                metadata = {
                    "learning_batch": f"cycle_{datetime.now().strftime('%Y%m%d_%H%M')}",
                    "text_index": i,
                    "source": "adaptive_learning"
                }
                
                if self.add_new_knowledge(text, metadata):
                    added_count += 1
            
            cycle_report["phase_results"]["knowledge_addition"] = {
                "attempted": len(new_texts),
                "successful": added_count,
                "success_rate": added_count / len(new_texts) if new_texts else 0
            }
            print(f"   çŸ¥è­˜è¿½åŠ : {added_count}/{len(new_texts)} æˆåŠŸ")
            
            # Phase 3: å­¦ç¿’å¾Œã®å“è³ªæ¸¬å®š
            print("\nğŸ“ˆ Phase 3: å­¦ç¿’å¾Œå“è³ªæ¸¬å®š")
            post_quality = self.assess_search_quality(test_queries)
            cycle_report["phase_results"]["post_learning_quality"] = post_quality
            print(f"   å­¦ç¿’å¾Œå“è³ª: {post_quality['overall_quality']:.3f}")
            
            # Phase 4: æ”¹å–„è©•ä¾¡
            quality_improvement = post_quality["overall_quality"] - pre_quality["overall_quality"]
            cycle_report["phase_results"]["improvement_analysis"] = {
                "quality_delta": quality_improvement,
                "improvement_percentage": (quality_improvement / pre_quality["overall_quality"] * 100) if pre_quality["overall_quality"] > 0 else 0,
                "learning_effective": quality_improvement > 0.01  # 1%ä»¥ä¸Šã®æ”¹å–„
            }
            
            print(f"\nğŸ¯ å­¦ç¿’åŠ¹æœ: {quality_improvement:+.3f} ({quality_improvement/pre_quality['overall_quality']*100:+.1f}%)")
            
            if quality_improvement > 0.01:
                self.learning_metrics["search_quality_improvements"] += 1
                print("   âœ… æœ‰åŠ¹ãªå­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«å®Œäº†")
            else:
                print("   âš ï¸ é™å®šçš„ãªå­¦ç¿’åŠ¹æœ")
            
            cycle_report["cycle_end"] = datetime.now().isoformat()
            cycle_report["overall_success"] = added_count > 0 and quality_improvement > 0
            
            return cycle_report
            
        except Exception as e:
            cycle_report["error"] = str(e)
            cycle_report["overall_success"] = False
            return cycle_report
    
    def continuous_learning_demo(self) -> Dict[str, Any]:
        """ç¶™ç¶šå­¦ç¿’ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        print("\nğŸš€ ChromaDB v4 ç¶™ç¶šå­¦ç¿’ãƒ‡ãƒ¢é–‹å§‹")
        print("="*60)
        
        demo_report = {
            "demo_start": datetime.now().isoformat(),
            "system_status": "unknown",
            "learning_cycles": []
        }
        
        if not self.initialize():
            demo_report["system_status"] = "initialization_failed"
            return demo_report
        
        demo_report["system_status"] = "initialized"
        demo_report["initial_document_count"] = self.collection.count()
        
        # å­¦ç¿’ç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
        learning_samples = [
            "ChromaDB v4ã®embeddingå•é¡Œã¯æ¤œç´¢ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§è§£æ±ºã§ãã¾ã™ã€‚",
            "MySisterDBã®æ‰‹æ³•ã‚’å¿œç”¨ã™ã‚‹ã“ã¨ã§ç¶™ç¶šå­¦ç¿’ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚", 
            "numpyé…åˆ—ã®ç›´æ¥æ“ä½œã‚’é¿ã‘ã‚‹ã“ã¨ã§å®‰å®šæ€§ãŒå‘ä¸Šã—ã¾ã™ã€‚",
            "æ¤œç´¢æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ãŸå“è³ªè©•ä¾¡ã«ã‚ˆã‚Šå­¦ç¿’åŠ¹æœã‚’æ¸¬å®šã§ãã¾ã™ã€‚"
        ]
        
        # ãƒ†ã‚¹ãƒˆç”¨ã‚¯ã‚¨ãƒª
        test_queries = [
            "ChromaDB å•é¡Œè§£æ±º",
            "ç¶™ç¶šå­¦ç¿’ æ‰‹æ³•",
            "numpy é…åˆ— å•é¡Œ",
            "æ¤œç´¢ å“è³ªè©•ä¾¡"
        ]
        
        # å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ
        cycle_result = self.adaptive_learning_cycle(learning_samples, test_queries)
        demo_report["learning_cycles"].append(cycle_result)
        
        demo_report["final_document_count"] = self.collection.count()
        demo_report["documents_learned"] = demo_report["final_document_count"] - demo_report["initial_document_count"]
        
        # æœ€çµ‚è©•ä¾¡
        if cycle_result.get("overall_success"):
            demo_report["demo_status"] = "SUCCESS"
            demo_report["conclusion"] = "ChromaDB v4ã§ç¶™ç¶šå­¦ç¿’ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™"
        else:
            demo_report["demo_status"] = "PARTIAL_SUCCESS"
            demo_report["conclusion"] = "åŸºæœ¬æ©Ÿèƒ½ã¯å‹•ä½œã—ã¦ã„ã¾ã™ãŒå­¦ç¿’åŠ¹æœã¯é™å®šçš„ã§ã™"
        
        print(f"\nğŸ‰ ãƒ‡ãƒ¢å®Œäº†: {demo_report['demo_status']}")
        print(f"ğŸ“Š å­¦ç¿’æ–‡æ›¸æ•°: {demo_report['documents_learned']}")
        print(f"ğŸ’¡ çµè«–: {demo_report['conclusion']}")
        
        return demo_report

def main():
    """ç¶™ç¶šå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    v4_db_path = r"F:\å‰¯æ¥­\VSC_WorkSpace\IrukaWorkspace\shared__ChromaDB_v4"
    
    learning_system = SearchBasedLearningSystem(v4_db_path)
    demo_report = learning_system.continuous_learning_demo()
    
    # çµæœä¿å­˜
    output_file = r"f:\å‰¯æ¥­\VSC_WorkSpace\MCP_ChromaDB00\chromadb_v4_continuous_learning_demo.json"
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(demo_report, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nğŸ’¾ ç¶™ç¶šå­¦ç¿’ãƒ‡ãƒ¢ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {output_file}")
    except Exception as e:
        print(f"âš ï¸ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å¤±æ•—: {e}")
    
    return demo_report

if __name__ == "__main__":
    report = main()
