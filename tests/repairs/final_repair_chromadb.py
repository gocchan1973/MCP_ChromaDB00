#!/usr/bin/env python3
"""
ChromaDBã®æœ€çµ‚ä¿®å¾©ãƒ„ãƒ¼ãƒ«
"""
import chromadb
from chromadb.config import Settings
from pathlib import Path
import json
from datetime import datetime
import shutil

def final_repair_chromadb(db_path: str, create_backup: bool = True):
    """ChromaDBã®æœ€çµ‚ä¿®å¾©"""
    print(f"ğŸ”§ ChromaDBæœ€çµ‚ä¿®å¾©: {db_path}")
    print("=" * 70)
    
    if create_backup:
        backup_path = f"{db_path}_backup_final_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        print(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆä¸­: {backup_path}")
        shutil.copytree(db_path, backup_path)
        print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†")
    
    try:
        client = chromadb.PersistentClient(
            path=db_path,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # sister_chat_historyã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å®Œå…¨å†æ§‹ç¯‰
        print(f"\nğŸ”„ sister_chat_historyã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å†æ§‹ç¯‰")
        print("-" * 50)
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        original_collection = client.get_collection("sister_chat_history")
        all_data = original_collection.get()
        
        ids = all_data.get('ids', [])
        documents = all_data.get('documents', [])
        metadatas = all_data.get('metadatas', [])
        
        print(f"ğŸ“„ å…ƒãƒ‡ãƒ¼ã‚¿å–å¾—: {len(ids)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
        normalized_metadatas = []
        for i, metadata in enumerate(metadatas):
            if metadata is None:
                metadata = {}
            
            # æ¨™æº–ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ä½œæˆ
            normalized_metadata = {
                'timestamp': metadata.get('timestamp', datetime.now().isoformat()),
                'type': metadata.get('type', 'conversation_summary'),
                'genres': metadata.get('genres', 'ãã®ä»–'),
                'summary_length': metadata.get('summary_length', 0),
                'original_length': metadata.get('original_length', 0),
                'updated_timestamp': metadata.get('updated_timestamp', ''),
                'update_reason': metadata.get('update_reason', '')
            }
            
            # ã™ã¹ã¦ã®å€¤ãŒNoneã§ãªã„ã“ã¨ã‚’ç¢ºèª
            for key, value in normalized_metadata.items():
                if value is None:
                    if key in ['summary_length', 'original_length']:
                        normalized_metadata[key] = 0
                    else:
                        normalized_metadata[key] = ''
            
            normalized_metadatas.append(normalized_metadata)
        
        print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–å®Œäº†")
        
        # å…ƒã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤
        print(f"ğŸ—‘ï¸ å…ƒã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‰Šé™¤ä¸­...")
        client.delete_collection("sister_chat_history")
        
        # æ–°ã—ã„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
        print(f"ğŸ†• æ–°ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆä¸­...")
        new_collection = client.create_collection("sister_chat_history")
        
        # æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        print(f"ğŸ“¥ ãƒ‡ãƒ¼ã‚¿è¿½åŠ ä¸­...")
        batch_size = 20  # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã—ã¦å®‰å…¨ã«å‡¦ç†
        
        for i in range(0, len(ids), batch_size):
            batch_ids = ids[i:i+batch_size]
            batch_docs = documents[i:i+batch_size]
            batch_metas = normalized_metadatas[i:i+batch_size]
            
            new_collection.add(
                ids=batch_ids,
                documents=batch_docs,
                metadatas=batch_metas
            )
            print(f"   ãƒãƒƒãƒ {i//batch_size + 1}/{(len(ids)-1)//batch_size + 1} å®Œäº†")
        
        print(f"âœ… ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å†æ§‹ç¯‰å®Œäº†")
        
        # æ¤œè¨¼
        print(f"\nğŸ” æœ€çµ‚æ¤œè¨¼")
        print("-" * 30)
        
        # å†æ§‹ç¯‰ã•ã‚ŒãŸã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç¢ºèª
        rebuilt_collection = client.get_collection("sister_chat_history")
        rebuilt_count = rebuilt_collection.count()
        
        print(f"ğŸ“Š å†æ§‹ç¯‰å¾Œãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {rebuilt_count}")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        sample = rebuilt_collection.get(limit=5)
        sample_metadatas = sample.get('metadatas', [])
        
        if sample_metadatas:
            expected_keys = {'timestamp', 'type', 'genres', 'summary_length', 'original_length', 'updated_timestamp', 'update_reason'}
            all_consistent = True
            
            for metadata in sample_metadatas:
                if not metadata or set(metadata.keys()) != expected_keys:
                    all_consistent = False
                    break
            
            if all_consistent:
                print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹é€ : å®Œå…¨ä¸€è²«")
                print(f"ğŸ“‹ æ¨™æº–ã‚­ãƒ¼: {sorted(expected_keys)}")
            else:
                print(f"âŒ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹é€ : ä¸æ•´åˆæ®‹å­˜")
        
        # å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æœ€çµ‚ç¢ºèª
        print(f"\nğŸ“Š å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æœ€çµ‚çŠ¶æ…‹")
        print("-" * 30)
        
        collections = client.list_collections()
        for collection in collections:
            doc_count = collection.count()
            print(f"   {collection.name}: {doc_count}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
        
        print(f"\nğŸ‰ æœ€çµ‚ä¿®å¾©å®Œäº†!")
        print(f"   ä¿®å¾©æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        if create_backup:
            print(f"   ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_path}")
        
        return {
            "success": True,
            "rebuilt_documents": rebuilt_count,
            "backup_path": backup_path if create_backup else None,
            "repair_timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ æœ€çµ‚ä¿®å¾©ã‚¨ãƒ©ãƒ¼: {e}")
        return {"success": False, "error": str(e)}

if __name__ == "__main__":
    target_path = r"F:\å‰¯æ¥­\VSC_WorkSpace\IrukaWorkspace\shared__ChromaDB"
    
    print(f"ğŸ”§ æœ€çµ‚ä¿®å¾©ã‚’é–‹å§‹ã—ã¾ã™")
    print(f"   sister_chat_historyã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Œå…¨å†æ§‹ç¯‰ã—ã¾ã™")
    
    # ä¿®å¾©å®Ÿè¡Œ
    result = final_repair_chromadb(target_path, create_backup=True)
    
    # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_file = Path(__file__).parent / f"chromadb_final_repair_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ ä¿®å¾©ãƒ­ã‚°ã¯ {output_file} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
