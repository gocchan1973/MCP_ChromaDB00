#!/usr/bin/env python3
"""
æ–°ã—ã„çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€çµ‚ç¢ºèª
"""
import chromadb
from chromadb.config import Settings
from pathlib import Path
import json
from datetime import datetime

def verify_new_database():
    """æ–°ã—ã„çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ¤œè¨¼"""
    
    db_path = r"F:\å‰¯æ¥­\VSC_WorkSpace\IrukaWorkspace\shared__ChromaDB_v4"
    
    print("ğŸ” æ–°ã—ã„çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ¤œè¨¼é–‹å§‹")
    print("=" * 60)
    print(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹: {db_path}")
    print()
    
    try:
        # ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶š
        client = chromadb.PersistentClient(
            path=db_path,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§
        collections = client.list_collections()
        print(f"ğŸ“Š ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(collections)}")
        
        for collection in collections:
            print(f"\nğŸ“ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {collection.name}")
            print(f"   ID: {collection.id}")
            print(f"   ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {collection.metadata}")
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°
            doc_count = collection.count()
            print(f"   ğŸ“Š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {doc_count}")
            
            if doc_count > 0:                # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
                try:
                    search_test = collection.query(
                        query_texts=["Python ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°"],
                        n_results=5
                    )
                    
                    if search_test and search_test.get('documents'):
                        print(f"   âœ… æ¤œç´¢ãƒ†ã‚¹ãƒˆ: æˆåŠŸ ({len(search_test.get('documents', []))}ä»¶)")
                        
                        # æ¤œç´¢çµæœã®ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
                        search_docs = search_test.get('documents', [])
                        search_metadatas = search_test.get('metadatas', [])
                        if search_docs:
                            print(f"   ğŸ” æ¤œç´¢çµæœã‚µãƒ³ãƒ—ãƒ«:")
                            for idx, (doc, meta) in enumerate(zip(search_docs[:2], search_metadatas[:2] if search_metadatas else [])):
                                preview = doc[:50] + "..." if len(doc) > 50 else doc
                                source = meta.get('source_collection', 'Unknown') if meta else 'Unknown'
                                print(f"      {idx+1}. [{source}] {preview}")
                    else:
                        print(f"   âŒ æ¤œç´¢ãƒ†ã‚¹ãƒˆ: å¤±æ•—")
                    
                except Exception as e:
                    print(f"   âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                
                # ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
                sample = collection.get(limit=5)
                print(f"   ğŸ“„ ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:")
                
                source_counts = {}
                for i, (doc_id, document, metadata) in enumerate(zip(
                    sample.get('ids', []), 
                    sample.get('documents', []), 
                    sample.get('metadatas', [])
                )):
                    if i < 3:  # æœ€åˆã®3ä»¶ã‚’è¡¨ç¤º
                        preview = document[:60] + "..." if len(document) > 60 else document
                        source = metadata.get('source_collection', 'Unknown') if metadata else 'Unknown'
                        print(f"      {i+1}. [{source}] {preview}")
                    
                    # å…ƒã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
                    if metadata:
                        source = metadata.get('source_collection', 'Unknown')
                        source_counts[source] = source_counts.get(source, 0) + 1
                
                print(f"   ğŸ·ï¸  å…ƒã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åˆ¥å†…è¨³:")
                for source, count in source_counts.items():
                    print(f"      â€¢ {source}: {count}ä»¶")
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼åˆ†æ
                all_data = collection.get(include=['metadatas'], limit=100)
                all_metadatas = all_data.get('metadatas', [])
                
                if all_metadatas:
                    metadata_keys = set()
                    for meta in all_metadatas:
                        if meta:
                            metadata_keys.update(meta.keys())
                    print(f"   ğŸ”‘ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼: {sorted(list(metadata_keys))}")
        
        print(f"\nğŸ¯ æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
        print("=" * 40)
        print(f"âœ… çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ: æˆåŠŸ")
        print(f"ğŸ“Š ç·ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(collections)}")
        
        total_docs = sum(collection.count() for collection in collections)
        print(f"ğŸ“„ ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {total_docs}")
        
        # SQLiteãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
        sqlite_file = Path(db_path) / "chroma.sqlite3"
        if sqlite_file.exists():
            size_mb = sqlite_file.stat().st_size / (1024 * 1024)
            print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚º: {size_mb:.2f} MB")
        
        print(f"ğŸ•’ æ¤œè¨¼æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = verify_new_database()
    
    if success:
        print("\nğŸ‰ æ–°ã—ã„çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ¤œè¨¼ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ!")
        print("ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹: F:\\å‰¯æ¥­\\VSC_WorkSpace\\IrukaWorkspace\\shared__ChromaDB_v4")
        print("ğŸ“š çµ±åˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: sister_chat_history_v4")
    else:
        print("\nâŒ æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
