#!/usr/bin/env python3
"""
IrukaWorkspaceå†…ã®å…¨ChromaDBãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¯”è¼ƒåˆ†æ
"""
import chromadb
from chromadb.config import Settings
from pathlib import Path
import json
from datetime import datetime

def quick_analyze_db(db_path: Path):
    """ChromaDBã®ç°¡æ˜“åˆ†æ"""
    if not db_path.exists():
        return {"status": "not_found", "path": str(db_path)}
    
    sqlite_file = db_path / "chroma.sqlite3"
    if not sqlite_file.exists():
        return {"status": "no_sqlite", "path": str(db_path)}
    
    try:
        client = chromadb.PersistentClient(
            path=str(db_path),
            settings=Settings(anonymized_telemetry=False)
        )
        
        collections = client.list_collections()
        total_docs = 0
        collection_info = []
        
        for collection in collections:
            count = collection.count()
            total_docs += count
            collection_info.append({
                "name": collection.name,
                "count": count,
                "metadata": collection.metadata
            })
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        size_mb = sqlite_file.stat().st_size / (1024 * 1024)
        
        return {
            "status": "success",
            "path": str(db_path),
            "collections_count": len(collections),
            "total_documents": total_docs,
            "size_mb": round(size_mb, 2),
            "collections": collection_info
        }
        
    except Exception as e:
        return {
            "status": "error",
            "path": str(db_path),
            "error": str(e)
        }

def main():
    """å…¨ChromaDBãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åˆ†æ"""
    print("ğŸ” IrukaWorkspace ChromaDB çµ±åˆåˆ†æ")
    print("=" * 70)
    
    base_path = Path(r"F:\å‰¯æ¥­\VSC_WorkSpace\IrukaWorkspace")
    
    # åˆ†æå¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    db_directories = [
        "shared__ChromaDB",
        "shared__ChromaDB_v4", 
        "shared__ChromaDB_v4ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç„¡ã—",
        "shared__ChromaDBãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç„¡ã—",
        "shared_Chromadb",
        "shared_Chromadbãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç„¡ã—"
    ]
    
    results = {}
    total_dbs = 0
    total_collections = 0
    total_documents = 0
    
    for db_dir in db_directories:
        db_path = base_path / db_dir
        print(f"ğŸ“‚ åˆ†æä¸­: {db_dir}")
        
        result = quick_analyze_db(db_path)
        results[db_dir] = result
        
        if result["status"] == "success":
            total_dbs += 1
            total_collections += result["collections_count"]
            total_documents += result["total_documents"]
            
            print(f"   âœ… æ­£å¸¸: {result['collections_count']} ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³, {result['total_documents']} ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ, {result['size_mb']} MB")
            
            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è©³ç´°
            for col in result["collections"]:
                print(f"      - {col['name']}: {col['count']} docs")
                
        elif result["status"] == "not_found":
            print(f"   âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        elif result["status"] == "no_sqlite":
            print(f"   âš ï¸  SQLiteãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
        else:
            print(f"   ğŸ’¥ ã‚¨ãƒ©ãƒ¼: {result.get('error', 'Unknown error')}")
        
        print()
    
    # ç·æ‹¬
    print("ğŸ“Š ç·æ‹¬ãƒ¬ãƒãƒ¼ãƒˆ")
    print(f"   æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {total_dbs}/{len(db_directories)}")
    print(f"   ç·ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ•°: {total_collections}")
    print(f"   ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {total_documents}")
    print()
    
    # æ¨å¥¨äº‹é …
    print("ğŸ’¡ æ¨å¥¨äº‹é …")
    active_dbs = [k for k, v in results.items() if v["status"] == "success" and v["total_documents"] > 0]
    
    if len(active_dbs) > 1:
        print("   ğŸ”„ è¤‡æ•°ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
        print("   ğŸ“‹ ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚’æ¤œè¨ã—ã¦ãã ã•ã„:")
        for db in active_dbs:
            print(f"      - {db}: {results[db]['total_documents']} ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
    elif len(active_dbs) == 1:
        print(f"   âœ… ä¸»è¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {active_dbs[0]}")
        print("   ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿è“„ç©ãŒé †èª¿ã§ã™")
    else:
        print("   âš ï¸  ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("   ğŸ†• æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆã‚’æ¨å¥¨ã—ã¾ã™")
    
    # çµæœä¿å­˜
    output_file = Path(__file__).parent / f"workspace_chromadb_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            "analysis_date": datetime.now().isoformat(),
            "summary": {
                "total_directories": len(db_directories),
                "active_databases": total_dbs,
                "total_collections": total_collections,
                "total_documents": total_documents
            },
            "detailed_results": results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ æ¯”è¼ƒåˆ†æçµæœã¯ {output_file} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")

if __name__ == "__main__":
    main()
