#!/usr/bin/env python3
"""
ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç›´æ¥åˆ†æã®ãƒ†ã‚¹ãƒˆ
"""
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

import chromadb
import numpy as np
from datetime import datetime

def test_direct_embedding_analysis():
    """ç›´æ¥ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åˆ†æã‚’ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ” ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç›´æ¥åˆ†æãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    try:
        # ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ¥ç¶š
        db_path = "f:/å‰¯æ¥­/VSC_WorkSpace/IrukaWorkspace/shared__ChromaDB_"
        client = chromadb.PersistentClient(path=db_path)
        
        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å–å¾—
        collection = client.get_collection("sister_chat_history_temp_repair")
        doc_count = collection.count()
        print(f"ğŸ“Š å¯¾è±¡ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {collection.name} ({doc_count}ä»¶)")
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç›´æ¥å–å¾—
        print("ğŸ“¥ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç›´æ¥å–å¾—ä¸­...")
        sample_data = collection.get(limit=10, include=['embeddings'])
        embeddings = sample_data.get('embeddings', [])
        
        if not embeddings:
            print("âŒ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
            
        print(f"âœ… ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å–å¾—æˆåŠŸ: {len(embeddings)}ä»¶")
        
        # numpyé…åˆ—å¤‰æ›
        valid_embeddings = [emb for emb in embeddings if emb is not None]
        if not valid_embeddings:
            print("âŒ æœ‰åŠ¹ãªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãŒã‚ã‚Šã¾ã›ã‚“")
            return
            
        embeddings_array = np.array(valid_embeddings)
        print(f"ğŸ“ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å½¢çŠ¶: {embeddings_array.shape}")
        
        # çµ±è¨ˆåˆ†æ
        norms = np.linalg.norm(embeddings_array, axis=1)
        statistics = {
            "mean_norm": float(np.mean(norms)),
            "std_norm": float(np.std(norms)),
            "min_norm": float(np.min(norms)),
            "max_norm": float(np.max(norms)),
            "zero_vectors": int(np.sum(norms < 1e-10))
        }
        
        print("ğŸ“Š çµ±è¨ˆçµæœ:")
        for key, value in statistics.items():
            print(f"   {key}: {value}")
            
        # ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§åˆ†æ
        zero_elements = np.sum(np.abs(embeddings_array) < 1e-10)
        total_elements = embeddings_array.size
        sparsity = float(zero_elements / total_elements) if total_elements > 0 else 0.0
        
        print(f"ğŸ“ˆ ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§: {sparsity:.4f}")
        
        # é¡ä¼¼åº¦åˆ†æ
        similarities = []
        for i in range(min(5, len(valid_embeddings))):
            for j in range(i+1, min(5, len(valid_embeddings))):
                sim = np.dot(embeddings_array[i], embeddings_array[j]) / (
                    np.linalg.norm(embeddings_array[i]) * np.linalg.norm(embeddings_array[j]) + 1e-10
                )
                similarities.append(float(sim))
        
        if similarities:
            similarity_stats = {
                "avg_similarity": float(np.mean(similarities)),
                "min_similarity": float(np.min(similarities)),
                "max_similarity": float(np.max(similarities)),
                "std_similarity": float(np.std(similarities))
            }
            
            print("ğŸ”— é¡ä¼¼åº¦çµ±è¨ˆ:")
            for key, value in similarity_stats.items():
                print(f"   {key}: {value:.4f}")
        
        print("ğŸ‰ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç›´æ¥åˆ†ææˆåŠŸï¼")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_direct_embedding_analysis()
