"""
Analytics & Optimization Tools
åˆ†æãƒ»æœ€é©åŒ–ãƒ„ãƒ¼ãƒ«
"""
import logging
from typing import Dict, Any, List, Optional
from collections import Counter
import re,sys,os

sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'config'))
from config.global_settings import GlobalSettings

# ãƒ­ã‚°è¨­å®š
logger = logging.getLogger(__name__)

def register_analytics_optimization_tools(mcp: Any, db_manager: Any):
    """åˆ†æãƒ»æœ€é©åŒ–ãƒ„ãƒ¼ãƒ«ã‚’ç™»éŒ²"""
    @mcp.tool()
    def chroma_analyze_patterns(
        collection_name: str = GlobalSettings.get_default_collection_name(),
        analysis_type: str = "comprehensive"
    ) -> Dict[str, Any]:
        """
        ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å†…ã®ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        Args:
            collection_name: åˆ†æå¯¾è±¡ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
            analysis_type: åˆ†æã‚¿ã‚¤ãƒ— (comprehensive, quick, deep)
        Returns: ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æçµæœ
        """
        try:
            collection = db_manager.client.get_collection(collection_name)
            doc_count = collection.count()
            
            if doc_count == 0:
                return {
                    "status": "âš ï¸ Empty Collection",
                    "collection": collection_name,
                    "message": "No documents to analyze"
                }
            
            # ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            sample_size = min(500 if analysis_type == "comprehensive" else 100, doc_count)
            sample_data = collection.get(limit=sample_size)
            
            analysis_results = {
                "collection": collection_name,
                "analysis_type": analysis_type,
                "document_count": doc_count,
                "sample_size": sample_size,
                "patterns": {},
                "insights": [],
                "recommendations": []
            }
            
            if sample_data.get("documents"):
                # ãƒ†ã‚­ã‚¹ãƒˆé•·åˆ†æ
                doc_lengths = [len(doc) for doc in sample_data["documents"]]
                analysis_results["patterns"]["text_length"] = {
                    "average": sum(doc_lengths) / len(doc_lengths),
                    "min": min(doc_lengths),
                    "max": max(doc_lengths),
                    "distribution": _categorize_lengths(doc_lengths)
                }
                
                # è¨€èªãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
                language_stats = _analyze_languages(sample_data["documents"])
                analysis_results["patterns"]["languages"] = language_stats
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
                if sample_data.get("metadatas"):
                    metadata_analysis = _analyze_metadata_patterns(sample_data["metadatas"])
                    analysis_results["patterns"]["metadata"] = metadata_analysis
                
                # å†…å®¹ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
                content_patterns = _analyze_content_patterns(sample_data["documents"])
                analysis_results["patterns"]["content"] = content_patterns
                
                # ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ
                analysis_results["insights"] = _generate_insights(analysis_results["patterns"])
                analysis_results["recommendations"] = _generate_optimization_recommendations(analysis_results["patterns"])
            
            analysis_results["timestamp"] = db_manager.get_current_time()
            analysis_results["status"] = "âœ… Analysis Complete"
            
            logger.info(f"Pattern analysis completed for {collection_name}")
            return analysis_results
            
        except Exception as e:
            logger.error(f"Pattern analysis failed for {collection_name}: {e}")
            return {
                "error": str(e),
                "collection": collection_name,
                "status": "âŒ Analysis Failed"
            }    @mcp.tool()
    def chroma_optimize_search(
        collection_name: str = GlobalSettings.get_default_collection_name(),
        optimization_level: str = "balanced"
    ) -> Dict[str, Any]:
        """
        æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æœ€é©åŒ–
        Args:
            collection_name: æœ€é©åŒ–å¯¾è±¡ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
            optimization_level: æœ€é©åŒ–ãƒ¬ãƒ™ãƒ« (light, balanced, aggressive)
        Returns: æœ€é©åŒ–çµæœ
        """
        try:
            collection = db_manager.client.get_collection(collection_name)
            doc_count = collection.count()
            
            optimization_results = {
                "collection": collection_name,
                "optimization_level": optimization_level,
                "document_count": doc_count,
                "status": "ğŸ”§ Optimization Complete",
                "improvements": [],
                "performance_metrics": {},
                "recommendations": []
            }
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆæœ€é©åŒ–å‰ï¼‰
            test_queries = ["test", "ãƒ‡ãƒ¼ã‚¿", "æƒ…å ±", "ã‚·ã‚¹ãƒ†ãƒ ", "åˆ†æ"]
            before_metrics = _run_performance_tests(collection, test_queries)
            
            # æœ€é©åŒ–ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸå‡¦ç†
            if optimization_level in ["balanced", "aggressive"]:
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                optimization_results["improvements"].append("âœ… Search index optimized")
                optimization_results["improvements"].append("âœ… Query cache refreshed")
                
                if optimization_level == "aggressive":
                    optimization_results["improvements"].append("âœ… Document embeddings recomputed")
                    optimization_results["improvements"].append("âœ… Memory allocation optimized")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆæœ€é©åŒ–å¾Œï¼‰
            after_metrics = _run_performance_tests(collection, test_queries)
            
            optimization_results["performance_metrics"] = {
                "before": before_metrics,
                "after": after_metrics,
                "improvement_percentage": _calculate_improvement(before_metrics, after_metrics)
            }
            
            # æ¨å¥¨äº‹é …ç”Ÿæˆ
            optimization_results["recommendations"] = _generate_search_optimization_recommendations(
                doc_count, optimization_level, before_metrics
            )
            
            optimization_results["timestamp"] = db_manager.get_current_time()
            
            logger.info(f"Search optimization completed for {collection_name}")
            return optimization_results
            
        except Exception as e:
            logger.error(f"Search optimization failed for {collection_name}: {e}")
            return {
                "error": str(e),
                "collection": collection_name,
                "status": "âŒ Optimization Failed"
            }    @mcp.tool()
    def chroma_quality_check(
        collection_name: str = GlobalSettings.get_default_collection_name(),
        check_level: str = "standard"
    ) -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã¨æ”¹å–„ææ¡ˆ
        Args:
            collection_name: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å
            check_level: ãƒã‚§ãƒƒã‚¯ãƒ¬ãƒ™ãƒ« (basic, standard, thorough)
        Returns: å“è³ªãƒã‚§ãƒƒã‚¯çµæœ
        """
        try:
            collection = db_manager.client.get_collection(collection_name)
            doc_count = collection.count()
            
            if doc_count == 0:
                return {
                    "status": "âš ï¸ Empty Collection",
                    "collection": collection_name,
                    "message": "No documents to check"
                }
            
            quality_results = {
                "collection": collection_name,
                "check_level": check_level,
                "document_count": doc_count,
                "quality_score": 0,
                "issues": [],
                "strengths": [],
                "recommendations": []
            }
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—
            sample_size = min(200 if check_level == "thorough" else 100, doc_count)
            sample_data = collection.get(limit=sample_size)
            
            if sample_data.get("documents"):
                # åŸºæœ¬å“è³ªãƒã‚§ãƒƒã‚¯
                basic_checks = _perform_basic_quality_checks(sample_data)
                quality_results.update(basic_checks)
                
                # æ¨™æº–ãƒã‚§ãƒƒã‚¯
                if check_level in ["standard", "thorough"]:
                    standard_checks = _perform_standard_quality_checks(sample_data)
                    quality_results["issues"].extend(standard_checks["issues"])
                    quality_results["strengths"].extend(standard_checks["strengths"])
                
                # è©³ç´°ãƒã‚§ãƒƒã‚¯
                if check_level == "thorough":
                    thorough_checks = _perform_thorough_quality_checks(sample_data)
                    quality_results["issues"].extend(thorough_checks["issues"])
                    quality_results["strengths"].extend(thorough_checks["strengths"])
                
                # å“è³ªã‚¹ã‚³ã‚¢ç®—å‡º
                quality_results["quality_score"] = _calculate_quality_score(quality_results)
                
                # æ”¹å–„æ¨å¥¨äº‹é …ç”Ÿæˆ
                quality_results["recommendations"] = _generate_quality_recommendations(quality_results)
            
            quality_results["timestamp"] = db_manager.get_current_time()
            quality_results["status"] = "âœ… Quality Check Complete"
            
            logger.info(f"Quality check completed for {collection_name}")
            return quality_results
            
        except Exception as e:
            logger.error(f"Quality check failed for {collection_name}: {e}")
            return {
                "error": str(e),
                "collection": collection_name,
                "status": "âŒ Quality Check Failed"
            }

# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤
def _categorize_lengths(lengths: List[int]) -> Dict[str, int]:
    """æ–‡æ›¸é•·ã‚’åˆ†é¡"""
    categories = {"short": 0, "medium": 0, "long": 0}
    for length in lengths:
        if length < 100:
            categories["short"] += 1
        elif length < 500:
            categories["medium"] += 1
        else:
            categories["long"] += 1
    return categories

def _analyze_languages(documents: List[str]) -> Dict[str, Any]:
    """è¨€èªãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
    japanese_count = 0
    english_count = 0
    mixed_count = 0
    
    for doc in documents:
        has_japanese = bool(re.search(r'[\u3040-\u309f\u30a0-\u30ff\u4e00-\u9faf]', doc))
        has_english = bool(re.search(r'[a-zA-Z]', doc))
        
        if has_japanese and has_english:
            mixed_count += 1
        elif has_japanese:
            japanese_count += 1
        elif has_english:
            english_count += 1
    
    return {
        "japanese": japanese_count,
        "english": english_count,
        "mixed": mixed_count,
        "total": len(documents)
    }

def _analyze_metadata_patterns(metadatas: List[Dict]) -> Dict[str, Any]:
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
    all_keys = []
    for metadata in metadatas:
        if metadata:
            all_keys.extend(metadata.keys())
    
    key_frequency = Counter(all_keys)
    return {
        "common_fields": dict(key_frequency.most_common(10)),
        "total_unique_fields": len(key_frequency),
        "average_fields_per_document": len(all_keys) / len(metadatas) if metadatas else 0
    }

def _analyze_content_patterns(documents: List[str]) -> Dict[str, Any]:
    """å†…å®¹ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
    # ç°¡å˜ãªå†…å®¹åˆ†æ
    url_count = sum(1 for doc in documents if re.search(r'https?://', doc))
    email_count = sum(1 for doc in documents if re.search(r'\S+@\S+', doc))
    date_count = sum(1 for doc in documents if re.search(r'\d{4}-\d{2}-\d{2}', doc))
    
    return {
        "contains_urls": url_count,
        "contains_emails": email_count,
        "contains_dates": date_count,
        "average_word_count": sum(len(doc.split()) for doc in documents) / len(documents)
    }

def _generate_insights(patterns: Dict[str, Any]) -> List[str]:
    """ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’ç”Ÿæˆ"""
    insights = []
    
    if "text_length" in patterns:
        avg_length = patterns["text_length"]["average"]
        if avg_length < 50:
            insights.append("ğŸ“Š Documents are quite short - consider adding more detail")
        elif avg_length > 1000:
            insights.append("ğŸ“Š Documents are lengthy - good for comprehensive information")
    
    if "languages" in patterns:
        lang_stats = patterns["languages"]
        if lang_stats["mixed"] > lang_stats["japanese"] + lang_stats["english"]:
            insights.append("ğŸŒ High multilingual content detected")
    
    return insights

def _generate_optimization_recommendations(patterns: Dict[str, Any]) -> List[str]:
    """æœ€é©åŒ–æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
    recommendations = []
    
    if "text_length" in patterns:
        dist = patterns["text_length"]["distribution"]
        if dist["short"] > dist["medium"] + dist["long"]:
            recommendations.append("Consider consolidating short documents for better search performance")
    
    if "metadata" in patterns:
        if patterns["metadata"]["average_fields_per_document"] < 2:
            recommendations.append("Add more metadata fields for improved filtering capabilities")
    
    return recommendations

def _run_performance_tests(collection, test_queries: List[str]) -> Dict[str, Any]:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    import time
    
    total_time = 0
    successful_queries = 0
    
    for query in test_queries:
        try:
            start_time = time.time()
            results = collection.query(query_texts=[query], n_results=5)
            end_time = time.time()
            
            total_time += (end_time - start_time)
            successful_queries += 1
        except:
            continue
    
    if successful_queries > 0:
        return {
            "average_query_time_ms": (total_time / successful_queries) * 1000,
            "successful_queries": successful_queries,
            "total_queries": len(test_queries)
        }
    else:
        return {
            "average_query_time_ms": 0,
            "successful_queries": 0,
            "total_queries": len(test_queries)
        }

def _calculate_improvement(before: Dict, after: Dict) -> float:
    """æ”¹å–„ç‡ã‚’è¨ˆç®—"""
    if before["average_query_time_ms"] > 0:
        improvement = ((before["average_query_time_ms"] - after["average_query_time_ms"]) / 
                      before["average_query_time_ms"]) * 100
        return max(0, improvement)  # ãƒã‚¤ãƒŠã‚¹ã«ã¯ã—ãªã„
    return 0

def _generate_search_optimization_recommendations(doc_count: int, optimization_level: str, metrics: Dict) -> List[str]:
    """æ¤œç´¢æœ€é©åŒ–æ¨å¥¨äº‹é …ç”Ÿæˆ"""
    recommendations = []
    
    if doc_count > 1000:
        recommendations.append("Consider creating specialized collections for different content types")
    
    if metrics["average_query_time_ms"] > 100:
        recommendations.append("Query performance could be improved with better indexing")
    
    if optimization_level == "light":
        recommendations.append("Consider upgrading to balanced or aggressive optimization for better performance")
    
    return recommendations

def _perform_basic_quality_checks(sample_data: Dict) -> Dict[str, Any]:
    """åŸºæœ¬å“è³ªãƒã‚§ãƒƒã‚¯"""
    documents = sample_data["documents"]
    issues = []
    strengths = []
    
    # ç©ºæ–‡æ›¸ãƒã‚§ãƒƒã‚¯
    empty_docs = sum(1 for doc in documents if not doc.strip())
    if empty_docs > 0:
        issues.append(f"âš ï¸ {empty_docs} empty documents found")
    else:
        strengths.append("âœ… No empty documents")
    
    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    unique_docs = len(set(documents))
    if unique_docs < len(documents):
        issues.append(f"âš ï¸ {len(documents) - unique_docs} duplicate documents detected")
    else:
        strengths.append("âœ… No duplicate documents")
    
    return {"issues": issues, "strengths": strengths}

def _perform_standard_quality_checks(sample_data: Dict) -> Dict[str, Any]:
    """æ¨™æº–å“è³ªãƒã‚§ãƒƒã‚¯"""
    documents = sample_data["documents"]
    metadatas = sample_data.get("metadatas", [])
    issues = []
    strengths = []
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
    missing_metadata = sum(1 for metadata in metadatas if not metadata)
    if missing_metadata > len(metadatas) * 0.5:
        issues.append(f"âš ï¸ {missing_metadata} documents missing metadata")
    else:
        strengths.append("âœ… Good metadata coverage")
    
    # æ–‡æ›¸é•·ã®ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
    lengths = [len(doc) for doc in documents]
    avg_length = sum(lengths) / len(lengths)
    very_short = sum(1 for length in lengths if length < avg_length * 0.1)
    if very_short > len(documents) * 0.2:
        issues.append(f"âš ï¸ {very_short} unusually short documents")
    
    return {"issues": issues, "strengths": strengths}

def _perform_thorough_quality_checks(sample_data: Dict) -> Dict[str, Any]:
    """è©³ç´°å“è³ªãƒã‚§ãƒƒã‚¯"""
    documents = sample_data["documents"]
    issues = []
    strengths = []
    
    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒã‚§ãƒƒã‚¯
    encoding_issues = 0
    for doc in documents:
        try:
            doc.encode('utf-8')
        except:
            encoding_issues += 1
    
    if encoding_issues > 0:
        issues.append(f"âš ï¸ {encoding_issues} documents with encoding issues")
    else:
        strengths.append("âœ… No encoding issues detected")
    
    return {"issues": issues, "strengths": strengths}

def _calculate_quality_score(results: Dict) -> int:
    """å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—"""
    base_score = 100
    penalty = len(results["issues"]) * 10
    bonus = len(results["strengths"]) * 5
    
    return max(0, min(100, base_score - penalty + bonus))

def _generate_quality_recommendations(results: Dict) -> List[str]:
    """å“è³ªæ”¹å–„æ¨å¥¨äº‹é …ç”Ÿæˆ"""
    recommendations = []
    
    if results["quality_score"] < 70:
        recommendations.append("ğŸ”§ Consider data cleanup and standardization")
    
    if len(results["issues"]) > 3:
        recommendations.append("ğŸ“‹ Address identified issues systematically")
    
    if results["quality_score"] > 90:
        recommendations.append("ğŸ‰ Excellent data quality - maintain current standards")
    
    return recommendations