#!/usr/bin/env python3
"""
NumPyé…åˆ—ãƒã‚°ã‚’å®Œå…¨ã«å›é¿ã—ãŸå®‰å…¨ãªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åˆ†æãƒ„ãƒ¼ãƒ«
MCPã‚µãƒ¼ãƒãƒ¼ç’°å¢ƒã§ã®åˆ¶ç´„ã‚’è€ƒæ…®ã—ãŸå®Ÿç”¨çš„ãªä»£æ›¿å®Ÿè£…
"""

import math
import json
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime

class SafeEmbeddingAnalyzer:
    """NumPyé…åˆ—ãƒã‚°ã‚’å®Œå…¨ã«å›é¿ã—ãŸå®‰å…¨ãªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, collection):
        self.collection = collection
        self.analysis_timestamp = datetime.now().isoformat()
    
    def analyze_embeddings_safe(self, analysis_type: str = "statistical", sample_size: int = 50) -> Dict[str, Any]:
        """
        NumPyé…åˆ—ãƒã‚°ã‚’å®Œå…¨ã«å›é¿ã—ãŸã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åˆ†æ
        
        Args:
            analysis_type: åˆ†æã‚¿ã‚¤ãƒ— (statistical, similarity, basic)
            sample_size: åˆ†æã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º
            
        Returns:
            å®‰å…¨ãªåˆ†æçµæœ
        """
        result = {
            "analysis_type": analysis_type,
            "sample_size": sample_size,
            "method": "numpy_bug_safe_implementation",
            "timestamp": self.analysis_timestamp,
            "status": "success"
        }
        
        try:
            # Step 1: å®‰å…¨ãªãƒ‡ãƒ¼ã‚¿å–å¾—
            safe_data = self._get_safe_embedding_data(sample_size)
            result.update(safe_data)
            
            if safe_data.get("embeddings_available", False):
                # Step 2: åˆ†æã‚¿ã‚¤ãƒ—åˆ¥å‡¦ç†
                if analysis_type == "statistical":
                    stats = self._compute_safe_statistics(safe_data["embeddings"])
                    result["statistical_analysis"] = stats
                    
                elif analysis_type == "similarity":
                    similarity = self._compute_safe_similarity(safe_data["embeddings"])
                    result["similarity_analysis"] = similarity
                    
                elif analysis_type == "basic":
                    basic = self._compute_basic_info(safe_data["embeddings"])
                    result["basic_analysis"] = basic
                    
                # Step 3: å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
                result["quality_score"] = self._calculate_quality_score(result)
            
            return result
            
        except Exception as e:
            return {
                "status": "failed",
                "error": f"Safe embedding analysis failed: {str(e)}",
                "analysis_type": analysis_type,
                "timestamp": self.analysis_timestamp,
                "fallback_info": self._get_fallback_info()
            }
    
    def _get_safe_embedding_data(self, sample_size: int) -> Dict[str, Any]:
        """NumPyé…åˆ—ã‚’ä½¿ã‚ãªã„å®‰å…¨ãªãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            # åŸºæœ¬æƒ…å ±ã®ã¿å–å¾—ï¼ˆembeddingsé™¤å¤–ï¼‰
            basic_data = self.collection.get(limit=sample_size, include=['documents', 'metadatas', 'ids'])
            
            doc_count = len(basic_data.get('documents', []))
            
            # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å–å¾—ã®è©¦è¡Œï¼ˆæ…é‡ã«ï¼‰
            embeddings = []
            embeddings_available = False
            
            try:
                # 1ä»¶ãšã¤æ…é‡ã«ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å–å¾—
                for i in range(min(5, doc_count)):  # æœ€åˆã®5ä»¶ã®ã¿ãƒ†ã‚¹ãƒˆ
                    single_data = self.collection.get(
                        limit=1, 
                        offset=i,
                        include=['embeddings']
                    )
                    
                    if single_data and 'embeddings' in single_data:
                        emb = single_data['embeddings']
                        if emb and len(emb) > 0:
                            # NumPyé…åˆ—ãƒã‚§ãƒƒã‚¯ï¼ˆå‹åæ–‡å­—åˆ—ã§å®‰å…¨ç¢ºèªï¼‰
                            emb_type = str(type(emb[0]))
                            if 'numpy' not in emb_type.lower():
                                embeddings.append(list(emb[0]))  # ãƒªã‚¹ãƒˆã¨ã—ã¦è¿½åŠ 
                                embeddings_available = True
                            else:
                                # NumPyé…åˆ—ã®å ´åˆã¯æ‰‹å‹•å¤‰æ›
                                try:
                                    embeddings.append([float(x) for x in emb[0]])
                                    embeddings_available = True
                                except:
                                    break  # å¤‰æ›å¤±æ•—æ™‚ã¯ä¸­æ–­
                
            except Exception as emb_error:
                embeddings_available = False
                embeddings = []
            
            return {
                "document_count": doc_count,
                "embeddings_available": embeddings_available,
                "embeddings": embeddings,
                "embedding_dimensions": len(embeddings[0]) if embeddings else 0,
                "sample_obtained": len(embeddings)
            }
            
        except Exception as e:
            return {
                "document_count": 0,
                "embeddings_available": False,
                "embeddings": [],
                "error": str(e)
            }
    
    def _compute_safe_statistics(self, embeddings: List[List[float]]) -> Dict[str, Any]:
        """NumPyé…åˆ—ã‚’ä½¿ã‚ãªã„å®‰å…¨ãªçµ±è¨ˆè¨ˆç®—"""
        if not embeddings:
            return {"error": "No embeddings available for statistical analysis"}
        
        try:
            stats = {
                "total_vectors": len(embeddings),
                "vector_dimensions": len(embeddings[0]) if embeddings else 0,
                "analysis_method": "manual_computation"
            }
            
            # ãƒ™ã‚¯ãƒˆãƒ«ãƒãƒ«ãƒ è¨ˆç®—
            norms = []
            zero_vectors = 0
            
            for embedding in embeddings:
                norm_squared = sum(x * x for x in embedding)
                norm = math.sqrt(norm_squared)
                norms.append(norm)
                
                if norm < 1e-10:
                    zero_vectors += 1
            
            if norms:
                stats["norm_statistics"] = {
                    "mean_norm": sum(norms) / len(norms),
                    "min_norm": min(norms),
                    "max_norm": max(norms),
                    "std_norm": self._safe_std_calculation(norms),
                    "zero_vectors": zero_vectors
                }
            
            # ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§åˆ†æ
            total_elements = 0
            zero_elements = 0
            
            for embedding in embeddings:
                for value in embedding:
                    total_elements += 1
                    if abs(value) < 1e-10:
                        zero_elements += 1
            
            stats["sparsity_analysis"] = {
                "sparsity_ratio": zero_elements / total_elements if total_elements > 0 else 0,
                "total_elements": total_elements,
                "zero_elements": zero_elements
            }
            
            return stats
            
        except Exception as e:
            return {"error": f"Statistical computation failed: {str(e)}"}
    
    def _compute_safe_similarity(self, embeddings: List[List[float]]) -> Dict[str, Any]:
        """NumPyé…åˆ—ã‚’ä½¿ã‚ãªã„å®‰å…¨ãªé¡ä¼¼åº¦è¨ˆç®—"""
        if len(embeddings) < 2:
            return {"error": "Need at least 2 embeddings for similarity analysis"}
        
        try:
            similarities = []
            max_pairs = min(10, len(embeddings))  # æœ€å¤§10ãƒšã‚¢
            
            for i in range(max_pairs):
                for j in range(i + 1, max_pairs):
                    emb1, emb2 = embeddings[i], embeddings[j]
                    
                    # å†…ç©è¨ˆç®—
                    dot_product = sum(a * b for a, b in zip(emb1, emb2))
                    
                    # ãƒãƒ«ãƒ è¨ˆç®—
                    norm1 = math.sqrt(sum(x * x for x in emb1))
                    norm2 = math.sqrt(sum(x * x for x in emb2))
                    
                    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
                    if norm1 > 1e-10 and norm2 > 1e-10:
                        similarity = dot_product / (norm1 * norm2)
                        similarities.append(similarity)
            
            if similarities:
                return {
                    "similarity_pairs": len(similarities),
                    "avg_similarity": sum(similarities) / len(similarities),
                    "min_similarity": min(similarities),
                    "max_similarity": max(similarities),
                    "std_similarity": self._safe_std_calculation(similarities),
                    "analysis_method": "cosine_similarity_manual"
                }
            else:
                return {"error": "No valid similarity pairs computed"}
                
        except Exception as e:
            return {"error": f"Similarity computation failed: {str(e)}"}
    
    def _compute_basic_info(self, embeddings: List[List[float]]) -> Dict[str, Any]:
        """åŸºæœ¬çš„ãªæƒ…å ±ã®ã¿æä¾›"""
        return {
            "total_vectors": len(embeddings),
            "vector_dimensions": len(embeddings[0]) if embeddings else 0,
            "analysis_method": "basic_info_only",
            "note": "Basic information without complex computations"
        }
    
    def _safe_std_calculation(self, values: List[float]) -> float:
        """å®‰å…¨ãªæ¨™æº–åå·®è¨ˆç®—"""
        if len(values) < 2:
            return 0.0
        
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / len(values)
        return math.sqrt(variance)
    
    def _calculate_quality_score(self, analysis_result: Dict[str, Any]) -> int:
        """åˆ†æçµæœã‹ã‚‰å“è³ªã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        score = 50  # ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ
        if analysis_result.get("embeddings_available", False):
            score += 20
        
        # çµ±è¨ˆåˆ†ææˆåŠŸ
        if "statistical_analysis" in analysis_result:
            stats = analysis_result["statistical_analysis"]
            if "norm_statistics" in stats:
                score += 15
                # ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ãŒãªã„å ´åˆ
                if stats["norm_statistics"].get("zero_vectors", 0) == 0:
                    score += 10
        
        # é¡ä¼¼åº¦åˆ†ææˆåŠŸ
        if "similarity_analysis" in analysis_result:
            score += 15
        
        return min(100, score)
    
    def _get_fallback_info(self) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±"""
        try:
            count = self.collection.count()
            return {
                "collection_document_count": count,
                "fallback_method": "basic_count_only",
                "note": "Advanced analysis unavailable due to technical constraints"
            }
        except:
            return {
                "fallback_method": "minimal_info",
                "note": "Unable to access collection data"
            }


def create_safe_embedding_analyzer(collection) -> SafeEmbeddingAnalyzer:
    """SafeEmbeddingAnalyzerã®ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°"""
    return SafeEmbeddingAnalyzer(collection)


# ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
def test_safe_embedding_analysis():
    """å®‰å…¨ãªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åˆ†æã®ãƒ†ã‚¹ãƒˆ"""
    try:
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
        
        from src.fastmcp_modular_server import ChromaDBManager
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        db_manager = ChromaDBManager()
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ç¢ºèª
        if db_manager.client is None:
            raise Exception("ChromaDB client initialization failed")
            
        collection = db_manager.client.get_collection("sister_chat_history_temp_repair")
        
        # å®‰å…¨ãªåˆ†æå®Ÿè¡Œ
        analyzer = SafeEmbeddingAnalyzer(collection)
        
        print("ğŸ§ª å®‰å…¨ãªã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°åˆ†æãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # çµ±è¨ˆåˆ†æãƒ†ã‚¹ãƒˆ
        stats_result = analyzer.analyze_embeddings_safe("statistical", 5)
        print(f"âœ… çµ±è¨ˆåˆ†æ: {stats_result.get('status', 'unknown')}")
        
        # é¡ä¼¼åº¦åˆ†æãƒ†ã‚¹ãƒˆ
        sim_result = analyzer.analyze_embeddings_safe("similarity", 5)
        print(f"âœ… é¡ä¼¼åº¦åˆ†æ: {sim_result.get('status', 'unknown')}")
        
        # åŸºæœ¬åˆ†æãƒ†ã‚¹ãƒˆ
        basic_result = analyzer.analyze_embeddings_safe("basic", 5)
        print(f"âœ… åŸºæœ¬åˆ†æ: {basic_result.get('status', 'unknown')}")
        
        return {
            "statistical": stats_result,
            "similarity": sim_result,
            "basic": basic_result
        }
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return {"error": str(e)}


if __name__ == "__main__":
    test_safe_embedding_analysis()
